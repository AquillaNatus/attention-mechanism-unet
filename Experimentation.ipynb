{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Experimentation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FWumlmcL3r0a",
        "pqJrjauP846-",
        "DGvexk_lvq1b",
        "og7YgBCLct5T",
        "Wb_jgNjdurVl",
        "vDxQ-_Ao7NBG",
        "QJqa5zAobgr2",
        "IqNWFF1wyZtE",
        "EJbgqIFEvty2",
        "WrXjUZiI5oNH",
        "P5KsYCx34JdT",
        "PdPUGj0iCqX9",
        "hGZXjnnfiFU6",
        "HICnX_kEQDhR",
        "CKl_IU1q4yeE",
        "WDa_hakb42II",
        "ieuJPBse44cA"
      ],
      "machine_shape": "hm"
    },
    "interpreter": {
      "hash": "26284b83044cf6d18497d2f2bcb8891a6475cbd87428bcdc4981d4fbeeb38628"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit ('tf_macos': conda)",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWumlmcL3r0a"
      },
      "source": [
        "# Load Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfE3V9Af9v5e"
      },
      "source": [
        "# Import packages\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import PIL\n",
        "import pathlib\n",
        "import os\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.losses import *\n",
        "import requests\n",
        "!pip install pyunpack patool\n",
        "import pyunpack\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import sys\n",
        "\n",
        "!pip install rarfile segmentation-models git+https://github.com/davej23/image-segmentation-keras.git rioxarray\n",
        "from rarfile import RarFile\n",
        "import segmentation_models as sm\n",
        "from keras_segmentation.models import segnet\n",
        "from keras.applications import vgg16\n",
        "from sklearn.metrics import *\n",
        "import rioxarray as rxr\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOqejGEXQLZ2"
      },
      "source": [
        "# Specify whether to download data or read in\n",
        "download = True\n",
        "base_dir = r\"./Amazon Forest Dataset/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjNYvVXlC6Ja"
      },
      "source": [
        "# Download data\n",
        "\n",
        "if download:\n",
        "    url = 'https://zenodo.org/record/3233081/files/Amazon%20Forest%20Dataset.rar?download=1'\n",
        "    r = requests.get(url, allow_redirects=True)\n",
        "    open('data.rar', 'wb').write(r.content)\n",
        "\n",
        "    if sys.platform != 'darwin':\n",
        "        pyunpack.Archive('data.rar').extractall('')\n",
        "\n",
        "    else:\n",
        "        with RarFile('data.rar') as rf:\n",
        "            rf.extractall()\n",
        "\n",
        "base_dir = r\"./Amazon Forest Dataset/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fK90NPEP99zG"
      },
      "source": [
        "# Show example image from training data\n",
        "PIL.Image.open(r\"{}Training/images/Amazon_1110.tiff_25.tiff\".format(base_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xf8Iv5caGLEe",
        "outputId": "3ac01321-ade2-43c7-df05-50ef15958ba0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqJrjauP846-"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTEOTi_qwD0G"
      },
      "source": [
        "'''\n",
        "  Returns an image plot of mask prediction\n",
        "'''\n",
        "\n",
        "def reconstruct_image(model, image, rounded=False):\n",
        "\n",
        "  # Find model prediction\n",
        "  reconstruction = model.predict(image).reshape(image.shape[1], image.shape[2])\n",
        "  # Standardise between 0-1\n",
        "  reconstruction = reconstruction/np.max(reconstruction)\n",
        "\n",
        "  # Round to 0-1, binary pixel-by-pixel classification \n",
        "  if rounded:\n",
        "    reconstruction = np.round(reconstruction)\n",
        "\n",
        "  # Plot reconstructed mask (prediction)\n",
        "  plt.imshow(reconstruction) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxUiu0_OxMlo"
      },
      "source": [
        "'''\n",
        "  Returns array of mask prediction, given model and image\n",
        "'''\n",
        "def reconstruct_array(model, image, rounded=False):\n",
        "\n",
        "  # Find model prediction\n",
        "  reconstruction = model.predict(image).reshape(image.shape[1], image.shape[2])\n",
        "\n",
        "  if rounded:\n",
        "    reconstruction = np.round(reconstruction)\n",
        "\n",
        "  return reconstruction # Returns array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prjIhHN-r4o5"
      },
      "source": [
        "'''\n",
        "  Metric functions for evaluation\n",
        "'''\n",
        "\n",
        "def score_eval(model, image, mask): # Gives score of mask vs prediction\n",
        "  if type(image) != list:   \n",
        "    reconstruction = model.predict(image).reshape(mask.shape[1], mask.shape[2])\n",
        "    reconstruction = np.round(reconstruction).flatten()\n",
        "\n",
        "    return accuracy_score(mask.flatten(), reconstruction)\n",
        "\n",
        "  else: # If a list of images input, find accuracy for each\n",
        "    scores = []\n",
        "    for i in range(len(image)):\n",
        "      reconstruction = model.predict(image[i].reshape(1, 512, 512, 3))\n",
        "      reconstruction = np.round(reconstruction).flatten()\n",
        "\n",
        "      scores.append(accuracy_score(mask[i].flatten(), reconstruction))\n",
        "\n",
        "    return scores\n",
        "\n",
        "def score_eval2(model, image, mask): # Gives score of mask vs prediction\n",
        "  if type(image) != list:   \n",
        "    reconstruction = model.predict(image).reshape(mask.shape[1], mask.shape[2])\n",
        "    reconstruction = np.round(reconstruction).flatten()\n",
        "\n",
        "    return accuracy_score(mask.flatten(), reconstruction)\n",
        "\n",
        "  else: # If a list of images input, find accuracy for each\n",
        "    scores = []\n",
        "    for i in range(len(image)):\n",
        "      reconstruction = model.predict(image[i].reshape(1, 512, 512, 4))\n",
        "      reconstruction = np.round(reconstruction).flatten()\n",
        "\n",
        "      scores.append(accuracy_score(mask[i].flatten(), reconstruction))\n",
        "\n",
        "    return scores\n",
        "\n",
        "def recall_eval(model, image, mask): # Find recall score\n",
        "  if type(image) != list:   \n",
        "    reconstruction = model.predict(image).reshape(mask.shape[1], mask.shape[2])\n",
        "    reconstruction = np.round(reconstruction).flatten()\n",
        "\n",
        "    return recall_score(mask.flatten(), reconstruction, average='weighted')\n",
        "\n",
        "  else: # If a list of images input, find accuracy for each\n",
        "    recall = []\n",
        "    for i in range(len(image)):\n",
        "        reconstruction = model.predict(image[i]).reshape(mask[i].shape[1], mask[i].shape[2])\n",
        "        reconstruction = np.round(reconstruction).flatten()\n",
        "\n",
        "        recall.append(recall_score(mask[i].flatten(), reconstruction, average='weighted'))\n",
        "\n",
        "    return recall\n",
        "\n",
        "def precision_eval(model, image, mask): # Find precision score\n",
        "  if type(image) != list:   \n",
        "    reconstruction = model.predict(image).reshape(mask.shape[1], mask.shape[2])\n",
        "    reconstruction = np.round(reconstruction).flatten()\n",
        "\n",
        "    return precision_score(mask.flatten(), reconstruction, average='weighted')\n",
        "\n",
        "  else: # If a list of images input, find accuracy for each\n",
        "    precision = []\n",
        "    for i in range(len(image)):\n",
        "        reconstruction = model.predict(image[i]).reshape(mask[i].shape[1], mask[i].shape[2])\n",
        "        reconstruction = np.round(reconstruction).flatten()\n",
        "\n",
        "        precision.append(precision_score(mask[i].flatten(), reconstruction, average='weighted'))\n",
        "\n",
        "    return precision\n",
        "\n",
        "def f1_score_eval(model, image, mask): # Find F1-score\n",
        "    prec = np.mean(precision_eval(model, image, mask))\n",
        "    rec = np.mean(recall_eval(model, image, mask))\n",
        "\n",
        "    if prec + rec == 0:\n",
        "        return 0\n",
        "\n",
        "    return 2 * (prec * rec) / (prec + rec)\n",
        "\n",
        "def f1_score_eval_basic(precision, recall):\n",
        "    prec = np.mean(precision)\n",
        "    rec = np.mean(recall)\n",
        "\n",
        "    if prec + rec == 0:\n",
        "        return 0\n",
        "\n",
        "    return 2 * (prec * rec) / (prec + rec)\n",
        "\n",
        "def produce_mask(image): # Outputs rounded image (binary)\n",
        "  return np.round(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGvexk_lvq1b"
      },
      "source": [
        "# Ingest and Process RGB Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLRxMrWmqaHw"
      },
      "source": [
        "# Ingest images\n",
        "\n",
        "## Training images\n",
        "training_images_list = os.listdir(r\"{}Training/images/\".format(base_dir))\n",
        "training_masks_list = []\n",
        "training_images = []\n",
        "for n in training_images_list:\n",
        "  im = PIL.Image.open(r\"{}Training/images/{}\".format(base_dir,n))\n",
        "  training_images.append(im)\n",
        "  training_masks_list.append(n[:-5]+'.png')\n",
        "\n",
        "## Training masks\n",
        "training_masks = []\n",
        "for n in training_masks_list:\n",
        "  im = PIL.Image.open(r\"{}Training/masks/{}\".format(base_dir,n))\n",
        "  training_masks.append(im)\n",
        "\n",
        "## Test images\n",
        "test_images_list = os.listdir(r\"{}Test/\".format(base_dir))\n",
        "test_images = []\n",
        "for n in test_images_list:\n",
        "  im = PIL.Image.open(r\"{}Test/{}\".format(base_dir,n))\n",
        "  test_images.append(im)\n",
        "\n",
        "## Validation images\n",
        "validation_images_list = os.listdir(r\"{}Validation/images/\".format(base_dir))\n",
        "validation_masks_list = []\n",
        "validation_images = []\n",
        "for n in validation_images_list:\n",
        "  im = PIL.Image.open(r\"{}Validation/images/{}\".format(base_dir,n))\n",
        "  validation_images.append(im)\n",
        "  validation_masks_list.append(n[:-5]+'.png')\n",
        "\n",
        "## Validation masks\n",
        "validation_masks = []\n",
        "for n in validation_masks_list:\n",
        "  im = PIL.Image.open(r\"{}Validation/masks/{}\".format(base_dir,n))\n",
        "  validation_masks.append(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAGhNiaR0W98"
      },
      "source": [
        "# Pre-process data, normalise and reshape\n",
        "for i in range(len(training_images)):\n",
        "  training_images[i] = np.array(training_images[i])/255\n",
        "  training_images[i] = training_images[i].reshape(512,512,3)\n",
        "  training_images[i] = training_images[i].astype('float32')\n",
        "\n",
        "for i in range(len(training_masks)):\n",
        "  training_masks[i] = (np.array(training_masks[i])-1)\n",
        "  training_masks[i] = training_masks[i][:512,:512]\n",
        "  training_masks[i] = training_masks[i].reshape(512,512,1)\n",
        "  training_masks[i] = training_masks[i].astype('int')\n",
        "\n",
        "for i in range(len(validation_images)):\n",
        "  validation_images[i] = np.array(validation_images[i])/255\n",
        "  validation_images[i] = validation_images[i].reshape(1,512,512,3)\n",
        "  validation_images[i] = validation_images[i].astype('float32')\n",
        "\n",
        "for i in range(len(validation_masks)):\n",
        "  validation_masks[i] = np.array(validation_masks[i])-1\n",
        "  validation_masks[i] = validation_masks[i][:512,:512]\n",
        "  validation_masks[i] = validation_masks[i].reshape(1,512,512,1)\n",
        "  validation_masks[i] = validation_masks[i].astype('int')\n",
        "\n",
        "for i in range(len(test_images)):\n",
        "  test_images[i] = np.array(test_images[i])/255\n",
        "  test_images[i] = test_images[i].reshape(1,512,512,3)\n",
        "  test_images[i] = test_images[i].astype('float32')\n",
        "\n",
        "# Add some training images to validation data to increase size of validation set\n",
        "for i in range(25,30):\n",
        "  validation_images.append(training_images[i].reshape(1,512,512,3))\n",
        "  validation_masks.append(training_masks[i].reshape(1,512,512,1))\n",
        "\n",
        "# Remove five images from training data, which has been added to validation data\n",
        "training_images = training_images[0:25]\n",
        "training_masks = training_masks[0:25]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aMREQdk9_9R"
      },
      "source": [
        "# Create TensorFlow datasets for validation sets\n",
        "validation_df = tf.data.Dataset.from_tensor_slices((validation_images, validation_masks))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyaBlceQjvly"
      },
      "source": [
        "#\n",
        "# Data loader/generator from: https://github.com/bragagnololu/UNet-defmapping.git\n",
        "#\n",
        "\n",
        "def adjustData(img, mask, num_class):\n",
        "  \n",
        "    mask[mask > 0.5] = 1 # FOREST\n",
        "    mask[mask <= 0.5] = 0 # NON-FOREST\n",
        "\n",
        "    return (img,mask)\n",
        "\n",
        "def trainGenerator(batch_size,\n",
        "                   image_array,\n",
        "                   mask_array,\n",
        "                   aug_dict,\n",
        "                   image_save_prefix  = \"image\",\n",
        "                   mask_save_prefix  = \"mask\",\n",
        "                   num_class = 2,\n",
        "                   save_to_dir = None,\n",
        "                   target_size = (512,512),\n",
        "                   seed = 1):\n",
        "\n",
        "    image_datagen = ImageDataGenerator(**aug_dict)\n",
        "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
        "\n",
        "    image_generator = image_datagen.flow(image_array,\n",
        "                                           batch_size = batch_size,\n",
        "                                           save_to_dir = save_to_dir,\n",
        "                                           save_prefix = image_save_prefix,\n",
        "                                           seed = seed) \n",
        "\n",
        "    mask_generator = mask_datagen.flow(mask_array,\n",
        "                                           batch_size = batch_size,\n",
        "                                           save_to_dir = save_to_dir,\n",
        "                                           save_prefix = mask_save_prefix,\n",
        "                                           seed = seed)\n",
        "    \n",
        "    train_generator = zip(image_generator, mask_generator)\n",
        "    \n",
        "    for (img,mask) in train_generator: \n",
        "        img, mask = adjustData(img, mask, num_class)\n",
        "        yield (img, mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAJgv7qOkgzA"
      },
      "source": [
        "#\n",
        "# Produce generators for training images\n",
        "#\n",
        "\n",
        "t_images = np.stack(training_images)\n",
        "t_masks = np.stack(training_masks)\n",
        "\n",
        "v_images = np.stack(validation_images)\n",
        "v_masks = np.stack(validation_masks)\n",
        "\n",
        "# Set parameters for data augmentation\n",
        "data_gen_args = dict(rotation_range=180,\n",
        "                    width_shift_range=0.25,\n",
        "                    height_shift_range=0.25,\n",
        "                    shear_range=0.25,\n",
        "                    zoom_range=0.25,\n",
        "                    horizontal_flip=True,\n",
        "                    vertical_flip = True,\n",
        "                    fill_mode='reflect',\n",
        "                    )\n",
        "\n",
        "train = trainGenerator(1, t_images, t_masks, data_gen_args, save_to_dir=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mz6o3t3sveL"
      },
      "source": [
        "# Ingest and Process 4-band Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og7YgBCLct5T"
      },
      "source": [
        "## 4-band Amazon dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCffD7yhLlXX"
      },
      "source": [
        "download = True # True, if files don't already exist in same directory\n",
        "base_dir2 = r\"./AMAZON/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov76wahQcvj_"
      },
      "source": [
        "# Download data (Amazon)\n",
        "\n",
        "if download:\n",
        "    url = 'https://zenodo.org/record/4498086/files/AMAZON.rar?download=1'\n",
        "    r = requests.get(url, allow_redirects=True)\n",
        "    open('data2.rar', 'wb').write(r.content)\n",
        "\n",
        "    if sys.platform != 'darwin':\n",
        "        pyunpack.Archive('data2.rar').extractall('')\n",
        "\n",
        "    else:\n",
        "        with RarFile('data2.rar') as rf:\n",
        "            rf.extractall()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blN04l8svxjo"
      },
      "source": [
        "# Ingest images and normalise\n",
        "\n",
        "## Training images\n",
        "training_images_list2 = os.listdir(r\"{}Training/image/\".format(base_dir2))[0:250]\n",
        "training_masks_list2 = []\n",
        "training_images2 = []\n",
        "for n in training_images_list2:\n",
        "  training_masks_list2.append(n)\n",
        "  a = (np.array(rxr.open_rasterio(r\"{}Training/image/{}\".format(base_dir2,n))))\n",
        "  a = (a-np.min(a)) / (np.max(a)-np.min(a))\n",
        "  training_images2.append(a)\n",
        "\n",
        "## Training masks\n",
        "training_masks2 = []\n",
        "for n in training_masks_list2:\n",
        "  a = (np.array(rxr.open_rasterio(r\"{}Training/label/{}\".format(base_dir2,n))))\n",
        "  training_masks2.append(a)\n",
        "\n",
        "## Test images\n",
        "test_images_list2 = os.listdir(r\"{}Test/image/\".format(base_dir2))\n",
        "test_masks_list2 = []\n",
        "test_images2 = []\n",
        "for n in test_images_list2:\n",
        "  test_masks_list2.append(n)\n",
        "  a = (np.array(rxr.open_rasterio(r\"{}Test/image/{}\".format(base_dir2,n))))\n",
        "  a = (a-np.min(a)) / (np.max(a)-np.min(a))\n",
        "  test_images2.append(a)\n",
        "\n",
        "## Test masks\n",
        "test_masks2 = []\n",
        "for n in test_masks_list2:\n",
        "  a = (np.array(rxr.open_rasterio(r\"{}Test/mask/{}\".format(base_dir2,n))))\n",
        "  test_masks2.append(a)\n",
        "\n",
        "## Validation images\n",
        "validation_images_list2 = os.listdir(r\"{}Validation/images/\".format(base_dir2))\n",
        "validation_masks_list2 = []\n",
        "validation_images2 = []\n",
        "for n in validation_images_list2:\n",
        "  validation_masks_list2.append(n)\n",
        "  a = (np.array(rxr.open_rasterio(r\"{}Validation/images/{}\".format(base_dir2,n))))\n",
        "  a = (a-np.min(a)) / (np.max(a)-np.min(a))\n",
        "  validation_images2.append(a)\n",
        "\n",
        "## Validation masks\n",
        "validation_masks2 = []\n",
        "for n in validation_masks_list2:\n",
        "  a = (np.array(rxr.open_rasterio(r\"{}Validation/masks/{}\".format(base_dir2,n))))\n",
        "  validation_masks2.append(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmgCg7ZZZdNr"
      },
      "source": [
        "# Show example train image\n",
        "plt.imshow((np.array(rxr.open_rasterio(r\"{}Training/image/{}\".format(base_dir2,training_images_list2[20])))[0,:,:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZCs99gac5i3"
      },
      "source": [
        "# Pre-process data, reshaping and transposing\n",
        "for i in range(len(training_images2)):\n",
        "  training_images2[i] = training_images2[i].astype('float32')\n",
        "  training_images2[i] = training_images2[i].T\n",
        "\n",
        "for i in range(len(training_masks2)):\n",
        "  training_masks2[i] = training_masks2[i].reshape(1,512,512,1)\n",
        "  training_masks2[i] = training_masks2[i].T\n",
        "\n",
        "for i in range(len(validation_images2)):\n",
        "  validation_images2[i] = validation_images2[i].astype('float32')\n",
        "  validation_images2[i] = validation_images2[i].T\n",
        "\n",
        "for i in range(len(validation_masks2)):\n",
        "  validation_masks2[i] = validation_masks2[i].reshape(1,512,512,1)\n",
        "  validation_masks2[i] = validation_masks2[i].T\n",
        "\n",
        "for i in range(len(test_images2)):\n",
        "  test_images2[i] = test_images2[i].astype('float32')\n",
        "  test_images2[i] = test_images2[i].T\n",
        "\n",
        "for i in range(len(test_masks2)):\n",
        "  test_masks2[i] = test_masks2[i].reshape(1,512,512,1)\n",
        "  test_masks2[i] = test_masks2[i].T\n",
        "\n",
        "for i in range(len(training_images2)):\n",
        "  training_images2[i] = training_images2[i].reshape(-1,512,512,4)\n",
        "\n",
        "for i in range(len(validation_images2)):\n",
        "  validation_images2[i] = validation_images2[i].reshape(-1,512,512,4)\n",
        "\n",
        "for i in range(len(test_images2)):\n",
        "  test_images2[i] = test_images2[i].reshape(-1,512,512,4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZWqzWXDeHea"
      },
      "source": [
        "# Create TensorFlow datasets for training and validation sets\n",
        "train_df_4band_amazon = tf.data.Dataset.from_tensor_slices((training_images2[0:250], training_masks2[0:250]))\n",
        "validation_df_4band_amazon = tf.data.Dataset.from_tensor_slices((validation_images2, validation_masks2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wb_jgNjdurVl"
      },
      "source": [
        "## 4-band Atlantic Forest dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBDbTSSzLuk4"
      },
      "source": [
        "download = True # True if files don't already exist in same directory\n",
        "base_dir3 = r\"./ATLANTIC FOREST/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fr4p47-Kuvde"
      },
      "source": [
        "# Download data (Atlantic Forest)\n",
        "if download:\n",
        "    url = 'https://zenodo.org/record/4498086/files/ATLANTIC%20FOREST.rar?download=1'\n",
        "    r = requests.get(url, allow_redirects=True)\n",
        "    open('data3.rar', 'wb').write(r.content)\n",
        "\n",
        "    if sys.platform != 'darwin':\n",
        "        pyunpack.Archive('data3.rar').extractall('')\n",
        "\n",
        "    else:\n",
        "        with RarFile('data3.rar') as rf:\n",
        "            rf.extractall()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANUhzzdQvOaL"
      },
      "source": [
        "# Ingest images and normalise\n",
        "\n",
        "## Training images\n",
        "training_images_list3 = os.listdir(r\"{}Training/image/\".format(base_dir3))[0:250]\n",
        "training_masks_list3 = []\n",
        "training_images3 = []\n",
        "for n in training_images_list3:\n",
        "  training_masks_list3.append(n)\n",
        "  a = (np.array(rxr.open_rasterio(r\"{}Training/image/{}\".format(base_dir3,n))))\n",
        "  a = (a-np.min(a)) / (np.max(a)-np.min(a))\n",
        "  training_images3.append(a)\n",
        "\n",
        "## Training masks\n",
        "training_masks3 = []\n",
        "for n in training_masks_list3:\n",
        "  a = (np.array(rxr.open_rasterio(r\"{}Training/label/{}\".format(base_dir3,n))))\n",
        "  training_masks3.append(a)\n",
        "\n",
        "## Test images\n",
        "test_images_list3 = os.listdir(r\"{}Test/image/\".format(base_dir3))\n",
        "test_masks_list3 = []\n",
        "test_images3 = []\n",
        "for n in test_images_list3:\n",
        "  test_masks_list3.append(n)\n",
        "  a = (np.array(rxr.open_rasterio(r\"{}Test/image/{}\".format(base_dir3,n))))\n",
        "  a = (a-np.min(a)) / (np.max(a)-np.min(a))\n",
        "  test_images3.append(a)\n",
        "\n",
        "## Test masks\n",
        "test_masks3 = []\n",
        "for n in test_masks_list3:\n",
        "  a = (np.array(rxr.open_rasterio(r\"{}Test/mask/{}\".format(base_dir3,n))))\n",
        "  test_masks3.append(a)\n",
        "\n",
        "## Validation images\n",
        "validation_images_list3 = os.listdir(r\"{}Validation/images/\".format(base_dir3))\n",
        "validation_masks_list3 = []\n",
        "validation_images3 = []\n",
        "for n in validation_images_list3:\n",
        "  validation_masks_list3.append(n)\n",
        "  a = (np.array(rxr.open_rasterio(r\"{}Validation/images/{}\".format(base_dir3,n))))\n",
        "  a = (a-np.min(a)) / (np.max(a)-np.min(a))\n",
        "  validation_images3.append(a)\n",
        "\n",
        "## Validation masks\n",
        "validation_masks3 = []\n",
        "for n in validation_masks_list3:\n",
        "  a = (np.array(rxr.open_rasterio(r\"{}Validation/masks/{}\".format(base_dir3,n))))\n",
        "  validation_masks3.append(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L31I43OJxMVU"
      },
      "source": [
        "# Pre-process data, reshaping and transposing\n",
        "for i in range(len(training_images3)):\n",
        "  training_images3[i] = training_images3[i].astype('float32')\n",
        "  training_images3[i] = training_images3[i].T\n",
        "\n",
        "for i in range(len(training_masks3)):\n",
        "  training_masks3[i] = training_masks3[i].reshape(1,512,512,1)\n",
        "  training_masks3[i] = training_masks3[i].T\n",
        "\n",
        "for i in range(len(validation_images3)):\n",
        "  validation_images3[i] = validation_images3[i].astype('float32')\n",
        "  validation_images3[i] = validation_images3[i].T\n",
        "\n",
        "for i in range(len(validation_masks3)):\n",
        "  validation_masks3[i] = validation_masks3[i].reshape(1,512,512,1)\n",
        "  validation_masks3[i] = validation_masks3[i].T\n",
        "\n",
        "for i in range(len(test_images3)):\n",
        "  test_images3[i] = test_images3[i].astype('float32')\n",
        "  test_images3[i] = test_images3[i].T\n",
        "\n",
        "for i in range(len(test_masks3)):\n",
        "  test_masks3[i] = test_masks3[i].reshape(1,512,512,1)\n",
        "  test_masks3[i] = test_masks3[i].T\n",
        "\n",
        "\n",
        "for i in range(len(training_images3)):\n",
        "  training_images3[i] = training_images3[i].reshape(-1,512,512,4)\n",
        "\n",
        "for i in range(len(validation_images3)):\n",
        "  validation_images3[i] = validation_images3[i].reshape(-1,512,512,4)\n",
        "\n",
        "for i in range(len(test_images3)):\n",
        "  test_images3[i] = test_images3[i].reshape(-1,512,512,4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn73cK3QE9fN"
      },
      "source": [
        "# Plot example training image first band\n",
        "plt.imshow(training_images3[0].reshape(512,512,4)[:,:,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n-tBTsjyL5q"
      },
      "source": [
        "# Create TensorFlow datasets for training and validation sets\n",
        "train_df_4band_atlantic = tf.data.Dataset.from_tensor_slices((training_images3[0:250], training_masks3[0:250]))\n",
        "validation_df_4band_atlantic = tf.data.Dataset.from_tensor_slices((validation_images3, validation_masks3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCp3t2JSyQ9O"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDxQ-_Ao7NBG"
      },
      "source": [
        "## U-Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--tUx5qNR0Q4"
      },
      "source": [
        "'''\n",
        "  Convolutional block with set parameters and activation layer after\n",
        "'''\n",
        "\n",
        "def convBlock(input, filters, kernel, kernel_init='he_normal', act='relu', transpose=False):\n",
        "  if transpose == False:\n",
        "    #conv = ZeroPadding2D((1,1))(input)\n",
        "    conv = Conv2D(filters, kernel, padding = 'same', kernel_initializer = kernel_init)(input)\n",
        "  else:\n",
        "    #conv = ZeroPadding2D((1,1))(input)\n",
        "    conv = Conv2DTranspose(filters, kernel, padding = 'same', kernel_initializer = kernel_init)(input)\n",
        "\n",
        "  conv = Activation(act)(conv)\n",
        "  return conv\n",
        "  \n",
        "'''\n",
        "  U-Net model\n",
        "'''\n",
        "\n",
        "def UNet(trained_weights = None, input_size = (512,512,3), drop_rate = 0.25, lr=0.0001):\n",
        "\n",
        "    ## Can add pretrained weights by specifying 'trained_weights'\n",
        "\n",
        "    # Input layer\n",
        "    inputs = Input(input_size, batch_size=1)\n",
        "\n",
        "    ## Contraction phase\n",
        "    conv1 = convBlock(inputs, 64, 3)\n",
        "    conv1 = convBlock(conv1, 64, 3)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = convBlock(pool1, 128, 3)\n",
        "    conv2 = convBlock(conv2, 128, 3)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    #drop2 = Dropout(drop_rate)(pool2)\n",
        "\n",
        "    conv3 = convBlock(pool2, 256, 3)\n",
        "    conv3 = convBlock(conv3, 256, 3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    #drop3 = Dropout(drop_rate)(pool3)\n",
        "\n",
        "    conv4 = convBlock(pool3, 512, 3)\n",
        "    conv4 = convBlock(conv4, 512, 3)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "    #drop4 = Dropout(drop_rate)(pool4)\n",
        "\n",
        "    conv5 = convBlock(pool4, 1024, 3)\n",
        "    conv5 = convBlock(conv5, 1024, 3)\n",
        "\n",
        "    ## Expansion phase\n",
        "    up6 = (Conv2DTranspose(512, kernel_size=2, strides=2, kernel_initializer='he_normal')(conv5))\n",
        "    merge6 = concatenate([conv4,up6])\n",
        "    conv6 = convBlock(merge6, 512, 3)\n",
        "    conv6 = convBlock(conv6, 512, 3)\n",
        "    #conv6 = Dropout(drop_rate)(conv6)\n",
        "\n",
        "    up7 = (Conv2DTranspose(256, kernel_size=2, strides=2, kernel_initializer='he_normal')(conv6))\n",
        "    merge7 = concatenate([conv3,up7])\n",
        "    conv7 = convBlock(merge7, 256, 3)\n",
        "    conv7 = convBlock(conv7, 256, 3)\n",
        "    #conv7 = Dropout(drop_rate)(conv7)\n",
        "\n",
        "    up8 = (Conv2DTranspose(128, kernel_size=2, strides=2, kernel_initializer='he_normal')(conv7))\n",
        "    merge8 = concatenate([conv2,up8])\n",
        "    conv8 = convBlock(merge8, 128, 3)\n",
        "    conv8 = convBlock(conv8, 128, 3)\n",
        "    #conv8 = Dropout(drop_rate)(conv8)\n",
        "\n",
        "    up9 = (Conv2DTranspose(64, kernel_size=2, strides=2, kernel_initializer='he_normal')(conv8))\n",
        "    merge9 = concatenate([conv1,up9])\n",
        "    conv9 = convBlock(merge9, 64, 3)\n",
        "    conv9 = convBlock(conv9, 64, 3)\n",
        "\n",
        "    # Output layer\n",
        "    conv10 = convBlock(conv9, 1, 1, act='sigmoid')\n",
        "\n",
        "    model = Model(inputs, conv10)\n",
        "\n",
        "    model.compile(optimizer = adam_v2.Adam(learning_rate = lr), loss = 'binary_crossentropy', metrics = ['accuracy', 'mse'])\n",
        "\n",
        "    if trained_weights != None:\n",
        "    \tmodel.load_weights(trained_weights)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD6fODjlcLdG"
      },
      "source": [
        "# Print model layers and number of parameters\n",
        "UNet().summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJqa5zAobgr2"
      },
      "source": [
        "## Attention U-Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3uY93JpT_OZ"
      },
      "source": [
        "'''\n",
        "  Convolutional block with two conv layers and two activation layers\n",
        "'''\n",
        "\n",
        "def convBlock2(input, filters, kernel, kernel_init='he_normal', act='relu', transpose=False):\n",
        "  if transpose == False:\n",
        "    conv = Conv2D(filters, kernel, padding = 'same', kernel_initializer = kernel_init)(input)\n",
        "    conv = Activation(act)(conv)\n",
        "    conv = Conv2D(filters, kernel, padding = 'same', kernel_initializer = kernel_init)(conv)\n",
        "    conv = Activation(act)(conv)\n",
        "  else:\n",
        "    conv = Conv2DTranspose(filters, kernel, padding = 'same', kernel_initializer = kernel_init)(input)\n",
        "    conv = Activation(act)(conv)\n",
        "    conv = Conv2DTranspose(filters, kernel, padding = 'same', kernel_initializer = kernel_init)(conv)\n",
        "    conv = Activation(act)(conv)\n",
        "\n",
        "  return conv\n",
        "  \n",
        "'''\n",
        "  Attention block/mechanism\n",
        "'''\n",
        "def attention_block(x, gating, inter_shape, drop_rate=0.25):\n",
        "   \n",
        "    # Find shape of inputs\n",
        "    shape_x = K.int_shape(x)\n",
        "    shape_g = K.int_shape(gating)\n",
        "\n",
        "    ## Process x vector and gating signal\n",
        "    # x vector input and processing\n",
        "    theta_x = Conv2D(inter_shape, kernel_size = 1, strides = 1, padding='same', kernel_initializer='he_normal', activation=None)(x)\n",
        "    theta_x = MaxPooling2D((2,2))(theta_x)\n",
        "    shape_theta_x = K.int_shape(theta_x)\n",
        "\n",
        "    # gating signal \"\"\n",
        "    phi_g = Conv2D(inter_shape, kernel_size = 1, strides = 1, padding='same', kernel_initializer='he_normal', activation=None)(gating)\n",
        "    shape_phi_g = K.int_shape(phi_g)\n",
        "\n",
        "    # Add components\n",
        "    concat_xg = add([phi_g, theta_x])\n",
        "    act_xg = Activation('relu')(concat_xg)\n",
        "\n",
        "    # Apply convolution\n",
        "    psi = Conv2D(1, kernel_size = 1, strides = 1, padding='same', kernel_initializer='he_normal', activation=None)(act_xg)\n",
        "\n",
        "    # Apply sigmoid activation\n",
        "    sigmoid_xg = Activation('sigmoid')(psi)\n",
        "    shape_sigmoid = K.int_shape(sigmoid_xg)\n",
        "\n",
        "    # UpSample and resample to correct size\n",
        "    upsample_psi = UpSampling2D(interpolation='bilinear', size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg)\n",
        "    upsample_psi = tf.broadcast_to(upsample_psi, shape=shape_x)\n",
        "    y = multiply([upsample_psi, x])\n",
        "\n",
        "    return y\n",
        "\n",
        "\n",
        "'''\n",
        "  Attention U-Net model\n",
        "'''\n",
        "\n",
        "def UNetAM(trained_weights = None, input_size = (512,512,3), drop_rate = 0.25, lr=0.0001, filter_base=16):\n",
        "\n",
        "    ## Can add pretrained weights by specifying 'trained_weights'\n",
        "\n",
        "    # Input layer\n",
        "    inputs = Input(input_size, batch_size=1)\n",
        "\n",
        "    ## Contraction phase\n",
        "    conv = convBlock2(inputs, filter_base, 3)\n",
        "    #conv0 = Dropout(drop_rate)(conv0)\n",
        "\n",
        "    conv0 = MaxPooling2D(pool_size=(2, 2))(conv)\n",
        "    conv0 = convBlock2(conv0, 2 * filter_base, 3)\n",
        "\n",
        "    pool0 = MaxPooling2D(pool_size=(2, 2))(conv0)\n",
        "    conv1 = convBlock2(pool0, 4 * filter_base, 3)\n",
        "    #conv1 = Dropout(drop_rate)(conv1)\n",
        "\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = convBlock2(pool1, 8 * filter_base, 3)\n",
        "    #conv2 = Dropout(drop_rate)(conv2)\n",
        "\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = convBlock2(pool2, 16 * filter_base, 3)\n",
        "    #conv3 = Dropout(drop_rate)(conv3)\n",
        "\n",
        "    ## Expansion phase\n",
        "    up4 = (Conv2DTranspose(8 * filter_base, kernel_size=2, strides=2, kernel_initializer='he_normal')(conv3))\n",
        "    merge4 = attention_block(conv2, conv3, 8 * filter_base, drop_rate) # Attention gate\n",
        "    conv4 = concatenate([up4, merge4])\n",
        "    conv4 = convBlock2(conv4, 8 * filter_base, 3)\n",
        "\n",
        "    up5 = (Conv2DTranspose(4 * filter_base, kernel_size=2, strides=2, kernel_initializer='he_normal')(conv4))\n",
        "    merge5 = attention_block(conv1, conv4, 4 * filter_base, drop_rate) # Attention gate\n",
        "    conv5 = concatenate([up5, merge5])\n",
        "    conv5 = convBlock2(conv5, 4 * filter_base, 3)\n",
        "\n",
        "    up6 = (Conv2DTranspose(2 * filter_base, kernel_size=2, strides=2, kernel_initializer='he_normal')(conv5))\n",
        "    merge6 = attention_block(conv0, conv5, 2 * filter_base, drop_rate) # Attention gate\n",
        "    conv6 = concatenate([up6, merge6])\n",
        "    conv6 = convBlock2(conv6, 2 * filter_base, 3)\n",
        "\n",
        "    up7 = (Conv2DTranspose(1 * filter_base, kernel_size=2, strides=2, kernel_initializer='he_normal')(conv6))\n",
        "    merge7 = attention_block(conv, conv6, 1 * filter_base, drop_rate) # Attention gate\n",
        "    conv7 = concatenate([up7, merge7])\n",
        "    conv7 = concatenate([up7, conv])\n",
        "    conv7 = convBlock2(conv7, 1 * filter_base, 3)\n",
        "\n",
        "    ## Output layer\n",
        "    out = convBlock(conv7, 1, 1, act='sigmoid')\n",
        "\n",
        "    model = Model(inputs, out)\n",
        "\n",
        "    model.compile(optimizer = adam_v2.Adam(learning_rate = lr), loss = binary_crossentropy, metrics = ['accuracy', 'mse'])\n",
        "\n",
        "    if trained_weights != None:\n",
        "    \tmodel.load_weights(trained_weights)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2fZD22p5xsF"
      },
      "source": [
        "# Print model layers and number of parameters\n",
        "UNetAM().summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqNWFF1wyZtE"
      },
      "source": [
        "# Train on RGB feature data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJbgqIFEvty2"
      },
      "source": [
        "## U-Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsAnxDvH1aIj"
      },
      "source": [
        "# Train U-Net with generator\n",
        "model_unet = UNet(input_size=(512,512,3), lr=0.0001)\n",
        "save_model = ModelCheckpoint('unet-3d.hdf5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "train = trainGenerator(1, t_images, t_masks, data_gen_args, save_to_dir=None)\n",
        "\n",
        "model_unet.fit(train, steps_per_epoch=100, epochs=30, validation_data = validation_df, callbacks=[save_model])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SCg0Km09uZ_"
      },
      "source": [
        "# Save model training history\n",
        "np.save('unet-3d-history.npy',model_unet.history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF9yrB7D4GXj"
      },
      "source": [
        "# Copy models to drive\n",
        "!cp unet-3d.hdf5 drive/MyDrive/Diss/\n",
        "!cp unet-3d-history.npy drive/MyDrive/Diss/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC25E6Bkmf9j"
      },
      "source": [
        "# Plot accuracy and loss \n",
        "\n",
        "## Accuracy\n",
        "plt.plot(model_unet.history.history['accuracy'])\n",
        "plt.plot(model_unet.history.history['val_accuracy'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "## Loss\n",
        "plt.plot(model_unet.history.history['loss'])\n",
        "plt.plot(model_unet.history.history['val_loss'])\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrXjUZiI5oNH"
      },
      "source": [
        "## Attention U-Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOeeBtkaXU03"
      },
      "source": [
        "# Train Attention U-Net with generator\n",
        "model_attention_unet = UNetAM(lr=0.0005, filter_base=16)\n",
        "save_model_am = ModelCheckpoint('unet-attention-3d.hdf5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "train = trainGenerator(1, t_images, t_masks, data_gen_args, save_to_dir=None)\n",
        "model_attention_unet.fit(train, steps_per_epoch=100, epochs=50, validation_data = validation_df, callbacks=[save_model_am])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azsRDL0eBMy7"
      },
      "source": [
        "# Save model history\n",
        "np.save('unet-attention-3d-history.npy',model_attention_unet.history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOjdBOjMucRJ"
      },
      "source": [
        "# Copy models to drive\n",
        "!cp unet-attention-3d.hdf5 drive/MyDrive/Diss/\n",
        "!cp unet-attention-3d-history.npy drive/MyDrive/Diss/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5KsYCx34JdT"
      },
      "source": [
        "# Train on 4-band data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdPUGj0iCqX9"
      },
      "source": [
        "## Train on 4-band Amazon data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGZXjnnfiFU6"
      },
      "source": [
        "### U-Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMXibzYiCtV6"
      },
      "source": [
        "# Train U-Net with generator\n",
        "model_unet_4band = UNet()\n",
        "save_model_4band = ModelCheckpoint('unet-4d.hdf5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "model_unet_4band.fit(train_df_4band_amazon, epochs = 20, validation_data = validation_df_4band_amazon, callbacks=[save_model_4band])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5Sf1pmCDI-c"
      },
      "source": [
        "# Save model history\n",
        "np.save('unet-4d-history.npy',model_unet_4band.history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM86ZMtryOi2"
      },
      "source": [
        "# Copy models to drive\n",
        "!cp unet-4d.hdf5 drive/MyDrive/Diss/\n",
        "!cp unet-4d-history.npy drive/MyDrive/Diss/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HICnX_kEQDhR"
      },
      "source": [
        "### Attention U-Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7bblQxyoyZd"
      },
      "source": [
        "# Train U-Net with generator\n",
        "model_attention_unet_4band = UNetAM(input_size=(512,512,4), filter_base=16, lr=0.0005)\n",
        "save_model_4band_attention = ModelCheckpoint('unet-attention-4d.hdf5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "model_attention_unet_4band.fit(train_df_4band_amazon, epochs = 60, validation_data = validation_df_4band_amazon, callbacks=[save_model_4band_attention])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU7s-wvYQgy7"
      },
      "source": [
        "# Save model history\n",
        "np.save('unet-attention-4d-history.npy',model_attention_unet_4band.history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8jeWN9XfEO-"
      },
      "source": [
        "# Copy models to drive\n",
        "!cp unet-attention-4d.hdf5 drive/MyDrive/Diss/\n",
        "!cp unet-attention-4d-history.npy drive/MyDrive/Diss/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKl_IU1q4yeE"
      },
      "source": [
        "## Train on 4-band Atlantic data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDa_hakb42II"
      },
      "source": [
        "### U-Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULAHseJg403h"
      },
      "source": [
        "# Train U-Net with generator\n",
        "model_unet_4band_atlantic = UNet()\n",
        "save_model_4band_atlantic = ModelCheckpoint('unet-4d-atlantic.hdf5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "model_unet_4band_atlantic.fit(train_df_4band_atlantic, epochs = 20, validation_data = validation_df_4band_atlantic, callbacks=[save_model_4band_atlantic])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saTWiRbk5NLN"
      },
      "source": [
        "# Save model history\n",
        "np.save('unet-4d-atlantic-history.npy',model_unet_4band_atlantic.history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNIQWXYMoNi7"
      },
      "source": [
        "# Copy models to drive\n",
        "!cp unet-4d-atlantic.hdf5 drive/MyDrive/Diss/\n",
        "!cp unet-4d-atlantic-history.npy drive/MyDrive/Diss/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieuJPBse44cA"
      },
      "source": [
        "### Attention U-Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEvQIolulSNp"
      },
      "source": [
        "# Train Attention U-Net with generator\n",
        "model_attention_unet_4band_atlantic = UNetAM(input_size=(512,512,4), filter_base=16, lr=0.0005)\n",
        "save_model_4band_attention_atlantic = ModelCheckpoint('unet-attention-4d-atlantic.hdf5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "model_attention_unet_4band_atlantic.fit(train_df_4band_atlantic, epochs = 60, validation_data = validation_df_4band_atlantic, callbacks=[save_model_4band_attention_atlantic])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vYhP4_25caq"
      },
      "source": [
        "# Save model history\n",
        "np.save('unet-attention-4d-atlantic-history.npy',model_attention_unet_4band_atlantic.history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMCaWw6On6_D"
      },
      "source": [
        "# Copy models to drive\n",
        "!cp unet-attention-4d-atlantic.hdf5 drive/MyDrive/Diss/\n",
        "!cp unet-attention-4d-atlantic-history.npy drive/MyDrive/Diss/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy4Z5mZf8sXf"
      },
      "source": [
        "# ResNet50-SegNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vYHnOX5OIqM"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwxSbQUQdaTY"
      },
      "source": [
        "# Forked code from: https://github.com/ykamikawa/tf-keras-SegNet\n",
        "\n",
        "from keras.layers import Layer\n",
        "\n",
        "'''\n",
        "  Unpooling using max pooling indices\n",
        "'''\n",
        "\n",
        "class MaxPoolingWithArgmax2D(Layer):\n",
        "    def __init__(self, pool_size=(2, 2), strides=(2, 2), padding=\"same\", **kwargs):\n",
        "        super(MaxPoolingWithArgmax2D, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        padding = 'same'\n",
        "        pool_size = (2,2)\n",
        "        strides = (2,2)\n",
        "        if K.backend() == \"tensorflow\":\n",
        "            ksize = [1, pool_size[0], pool_size[1], 1]\n",
        "            padding = padding.upper()\n",
        "            strides = [1, strides[0], strides[1], 1]\n",
        "            output, argmax = K.tf.nn.max_pool_with_argmax(\n",
        "                inputs, ksize=ksize, strides=strides, padding=padding\n",
        "            )\n",
        "        else:\n",
        "            errmsg = \"{} backend is not supported for layer {}\".format(\n",
        "                K.backend(), type(self).__name__\n",
        "            )\n",
        "            raise NotImplementedError(errmsg)\n",
        "        argmax = K.cast(argmax, K.floatx())\n",
        "        return [output, argmax]\n",
        "\n",
        "class MaxUnpooling2D(Layer):\n",
        "    def __init__(self, size=(2, 2), **kwargs):\n",
        "        super(MaxUnpooling2D, self).__init__(**kwargs)\n",
        "        self.size = size\n",
        "\n",
        "    def call(self, inputs, output_shape=None):\n",
        "        updates, mask = inputs[0], inputs[1]\n",
        "        with tf.compat.v1.variable_scope(self.name):\n",
        "            mask = K.cast(mask, \"int32\")\n",
        "            input_shape = K.tf.shape(updates, out_type=\"int32\")\n",
        "            #  calculation new shape\n",
        "            if output_shape is None:\n",
        "                output_shape = (\n",
        "                    input_shape[0],\n",
        "                    input_shape[1] * self.size[0],\n",
        "                    input_shape[2] * self.size[1],\n",
        "                    input_shape[3],\n",
        "                )\n",
        "            self.output_shape1 = output_shape\n",
        "\n",
        "            # calculation indices for batch, height, width and feature maps\n",
        "            one_like_mask = K.ones_like(mask, dtype=\"int32\")\n",
        "            batch_shape = K.concatenate([[input_shape[0]], [1], [1], [1]], axis=0)\n",
        "            batch_range = K.reshape(\n",
        "                K.tf.range(output_shape[0], dtype=\"int32\"), shape=batch_shape\n",
        "            )\n",
        "            b = one_like_mask * batch_range\n",
        "            y = mask // (output_shape[2] * output_shape[3])\n",
        "            x = (mask // output_shape[3]) % output_shape[2]\n",
        "            feature_range = K.tf.range(output_shape[3], dtype=\"int32\")\n",
        "            f = one_like_mask * feature_range\n",
        "\n",
        "            # transpose indices & reshape update values to one dimension\n",
        "            updates_size = K.tf.size(updates)\n",
        "            indices = K.transpose(K.reshape(K.stack([b, y, x, f]), [4, updates_size]))\n",
        "            values = K.reshape(updates, [updates_size])\n",
        "            ret = K.tf.scatter_nd(indices, values, output_shape)\n",
        "            return ret\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        mask_shape = input_shape[1]\n",
        "        return (\n",
        "            mask_shape[0],\n",
        "            mask_shape[1] * self.size[0],\n",
        "            mask_shape[2] * self.size[1],\n",
        "            mask_shape[3],\n",
        "        )\n",
        "\n",
        "# Custom version of MaxUnpooling2D\n",
        "# Takes raw layer values and outputs values\n",
        "# Takes tf.nn.max_pool_with_argmax output as input\n",
        "def unpool_with_indices(pool, indices, out_size=2):\n",
        "  print(pool)\n",
        "  print(indices)\n",
        "  # Create empty array of appropriate size\n",
        "  shape = np.array(np.shape(pool))\n",
        "  shape = np.array((shape[0], out_size * shape[1], out_size * shape[2], shape[3]))\n",
        "  out = np.zeros(shape)\n",
        "\n",
        "  # Make upsample\n",
        "  inds = np.array(indices).flatten()\n",
        "  outs = np.array(pool).flatten()\n",
        "  for i in range(len(inds)):\n",
        "    blk = inds[i] // (shape[2] * shape[3]) # Find which block to place numbers in\n",
        "    ln  = inds[i] - (blk * shape[3] * shape[2]) # Find which line\n",
        "    ln2 = ln // (shape[3]) # Find line\n",
        "    pos = ln % (shape[3]) # Find position\n",
        "    #print(blk, ln2, pos)\n",
        "    out[0][blk][ln2][pos] = outs[i]\n",
        "\n",
        "\n",
        "  #print(out.shape)\n",
        "  return (out)\n",
        "\n",
        "# Own custom code\n",
        "'''\n",
        "  ResNet Contraction Phase Block\n",
        "'''\n",
        "\n",
        "def resnetConvDownBlock(x, filter, kernel, act='relu'):\n",
        "  # Convolutional Block for encoding phase\n",
        "  for i in range(3):\n",
        "    x = ZeroPadding2D((1,1))(x)\n",
        "    x = Conv2D(filters = filter, kernel_size = kernel, kernel_initializer = 'he_normal')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "  return x\n",
        "\n",
        "'''\n",
        "  SegNet Expansion Phase Block\n",
        "'''\n",
        "def resnetConvUpBlock(x, skip_connection = None, filter = None, kernel = None, act='relu'):\n",
        "  # Convolutional block for decoding phase\n",
        "  \n",
        "  out = x\n",
        "\n",
        "  # Unpooling\n",
        "  out = UpSampling2D((2,2))(out)\n",
        "\n",
        "  # Conv Block\n",
        "  for i in range(3):\n",
        "    out = ZeroPadding2D((1,1))(out)\n",
        "    out = Conv2D(filters = filter, kernel_size = kernel, kernel_initializer = 'he_normal')(out)\n",
        "    out = Activation('relu')(out)\n",
        "\n",
        "  # Implement skip connection\n",
        "  if skip_connection != None:\n",
        "    out = Add()([out, skip_connection])\n",
        "\n",
        "  return out\n",
        "\n",
        "def ResNet50SegNet(input_size=(512,512,3), lr = 0.0001, filters = 64, kernel_sz = 3):\n",
        "\n",
        "  inputs = Input(input_size)\n",
        "\n",
        "  # Encoder\n",
        "  # Conv, Conv, Conv, MaxPool #1\n",
        "  block1 = resnetConvDownBlock(inputs, filter = filters, kernel = kernel_sz)\n",
        "  pool1, mask1 = MaxPoolingWithArgmax2D((2,2))(block1)\n",
        "  # Conv, Conv, Conv, MaxPool #2\n",
        "  block2 = resnetConvDownBlock(pool1, filter = 2 * filters, kernel = kernel_sz)\n",
        "  pool2, mask2 = MaxPoolingWithArgmax2D((2,2))(block2)\n",
        "  # Conv, Conv, Conv, MaxPool #3\n",
        "  block3 = resnetConvDownBlock(pool2, filter = 4 * filters, kernel = kernel_sz)\n",
        "  pool3, mask3 = MaxPoolingWithArgmax2D((2,2))(block3)\n",
        "  # Conv, Conv, Conv, MaxPool #4\n",
        "  block4 = resnetConvDownBlock(pool3, filter = 8 * filters, kernel = kernel_sz)\n",
        "  pool4, mask4 = MaxPoolingWithArgmax2D((2,2))(block4)\n",
        "  # Conv, Conv, Conv, MaxPool #5\n",
        "  block5 = resnetConvDownBlock(pool4, filter = 16 * filters, kernel = kernel_sz)\n",
        "  pool5, mask5 = MaxPoolingWithArgmax2D((2,2))(block5)\n",
        "\n",
        "  # Decoder\n",
        "  # ConvTranspose + Concat, Conv, Conv, Conv #1\n",
        "  block5_ = resnetConvUpBlock(pool5, filter = 16 * filters, kernel = kernel_sz)\n",
        "  # ConvTranspose + Concat, Conv, Conv, Conv #2\n",
        "  block4_ = resnetConvUpBlock(block5_, skip_connection = MaxUnpooling2D((2,2))([pool4, mask4]), filter = 8 * filters, kernel = kernel_sz)\n",
        "  # ConvTranspose + Concat, Conv, Conv, Conv #3\n",
        "  block3_ = resnetConvUpBlock(block4_, skip_connection = MaxUnpooling2D((2,2))([pool3, mask3]), filter = 4 * filters, kernel = kernel_sz)\n",
        "  # ConvTranspose + Concat, Conv, Conv, Conv #4\n",
        "  block2_ = resnetConvUpBlock(block3_, skip_connection = MaxUnpooling2D((2,2))([pool2, mask2]), filter = 2 * filters, kernel = kernel_sz)\n",
        "  # ConvTranspose + Concat, Conv, Conv, Conv #5\n",
        "  block1_ = resnetConvUpBlock(block2_, skip_connection = MaxUnpooling2D((2,2))([pool1, mask1]), filter = filters, kernel = kernel_sz)\n",
        "  \n",
        "  # Output\n",
        "  outputs = Conv2D(1, kernel_size = 1, strides = 1, kernel_initializer = 'he_normal')(block1_)\n",
        "  outputs = Activation('sigmoid')(outputs)\n",
        "\n",
        "  model = Model(inputs, outputs)\n",
        "  model.compile(optimizer = adam_v2.Adam(learning_rate = lr), loss = binary_crossentropy, metrics = ['accuracy', 'mse'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5epXYG6QYB2u"
      },
      "source": [
        "# Print model layers and number of parameters\n",
        "ResNet50SegNet().summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bArcR5Ha6l0U"
      },
      "source": [
        "## Train on RGB feature data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yqXR3Iie0jD"
      },
      "source": [
        "R = ResNet50SegNet()\n",
        "save_model_resnet = ModelCheckpoint('resnet50segnet-3d.hdf5', monitor='val_accuracy',verbose=1, save_best_only=True, save_weights_only=True)\n",
        "train = trainGenerator(1, t_images, t_masks, data_gen_args, save_to_dir=None)\n",
        "R.fit(train, validation_data = validation_df, epochs = 40, steps_per_epoch = 100, callbacks=[save_model_resnet])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVyJOLvE7jz4"
      },
      "source": [
        "# Save model history\n",
        "np.save('resnet50segnet-3d-history.npy',R.history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s--M2ygStGQi"
      },
      "source": [
        "# Copy models to drive\n",
        "!cp resnet50segnet-3d.hdf5 drive/MyDrive/Diss/models/\n",
        "!cp resnet50segnet-3d-history.npy drive/MyDrive/Diss/models/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMfIxvFD6xQm"
      },
      "source": [
        "## Train on 4-band data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHKvlxJo66T3"
      },
      "source": [
        "### Train on 4-band Amazon data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYeadji76_dU"
      },
      "source": [
        "R_4band = ResNet50SegNet(input_size=(512,512,4))\n",
        "save_model_resnet_4band = ModelCheckpoint('resnet50segnet-4d.hdf5', monitor='val_accuracy',verbose=1, save_best_only=True, save_weights_only=True)\n",
        "R_4band.fit(train_df_4band_amazon, validation_data = validation_df_4band_amazon, epochs = 20, callbacks=[save_model_resnet_4band])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LInS5I9M7n2O"
      },
      "source": [
        "# Save model history\n",
        "np.save('resnet50segnet-4d-history.npy', R_4band.history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA1hQvbz90PR"
      },
      "source": [
        "# Copy models to drive\n",
        "!cp resnet50segnet-4d.hdf5 drive/MyDrive/Diss/models/\n",
        "!cp resnet50segnet-4d-history.npy drive/MyDrive/Diss/models/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGNdCz0a68lZ"
      },
      "source": [
        "### Train on 4-band Atlantic data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyibZJTeno4p"
      },
      "source": [
        "R_4band_atlantic = ResNet50SegNet(input_size=(512,512,4))\n",
        "save_model_resnet_4band_atlantic = ModelCheckpoint('resnet50segnet-4d-atlantic.hdf5', monitor='val_accuracy',verbose=1, save_best_only=True, save_weights_only=True)\n",
        "R_4band_atlantic.fit(train_df_4band_atlantic, validation_data = validation_df_4band_atlantic, epochs = 30, callbacks=[save_model_resnet_4band_atlantic])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAo4JFJS7s88"
      },
      "source": [
        "# Save model history\n",
        "np.save('resnet50segnet-4d-history-atlantic.npy', R_4band_atlantic.history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfnpKigS95_2"
      },
      "source": [
        "# Copy models to drive\n",
        "!cp resnet50segnet-4d-atlantic.hdf5 drive/MyDrive/Diss/models/\n",
        "!cp resnet50segnet-4d-history-atlantic.npy drive/MyDrive/Diss/models/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjAKXzzskqVl"
      },
      "source": [
        "# FCN32-VGG16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0mnVbG4OEeI"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7843cUJ9_oeS"
      },
      "source": [
        "# Code forked and modified from: https://github.com/divamgupta/image-segmentation-keras\n",
        "\n",
        "'''\n",
        "  FCN32-VGG16 model\n",
        "'''\n",
        "\n",
        "def fcn_32(input_size = (512,512,3), lr = 0.0001, drop_rate = 0):\n",
        "  \n",
        "    kernel = 3\n",
        "    filter_size = 64\n",
        "    pad = 1\n",
        "    pool_size = 2\n",
        "\n",
        "    IMAGE_ORDERING = 'channels_last'\n",
        "    # Input\n",
        "    inputs = Input(shape=input_size)\n",
        "\n",
        "    x = inputs\n",
        "    levels = []\n",
        "\n",
        "    ## Encoder\n",
        "    # Block 1\n",
        "    x = Conv2D(64, (3, 3), padding='same',\n",
        "               name='block1_conv1', data_format=IMAGE_ORDERING)(inputs)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(64, (3, 3), padding='same',\n",
        "               name='block1_conv2', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool',\n",
        "                     data_format=IMAGE_ORDERING)(x)\n",
        "    levels.append(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2D(128, (3, 3), padding='same',\n",
        "               name='block2_conv1', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(128, (3, 3), padding='same',\n",
        "               name='block2_conv2', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool',\n",
        "                     data_format=IMAGE_ORDERING)(x)\n",
        "    levels.append(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = Conv2D(256, (3, 3), padding='same',\n",
        "               name='block3_conv1', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(256, (3, 3), padding='same',\n",
        "               name='block3_conv2', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(256, (3, 3), padding='same',\n",
        "               name='block3_conv3', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool',\n",
        "                     data_format=IMAGE_ORDERING)(x)\n",
        "    levels.append(x)\n",
        "\n",
        "    # Block 4\n",
        "    x = Conv2D(512, (3, 3), padding='same',\n",
        "               name='block4_conv1', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(512, (3, 3), padding='same',\n",
        "               name='block4_conv2', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(512, (3, 3), padding='same',\n",
        "               name='block4_conv3', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool',\n",
        "                     data_format=IMAGE_ORDERING)(x)\n",
        "    levels.append(x)\n",
        "\n",
        "    # Block 5\n",
        "    x = Conv2D(512, (3, 3), padding='same',\n",
        "               name='block5_conv1', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(512, (3, 3), padding='same',\n",
        "               name='block5_conv2', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(512, (3, 3), padding='same',\n",
        "               name='block5_conv3', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool',\n",
        "                     data_format=IMAGE_ORDERING)(x)\n",
        "\n",
        "    levels.append(x)\n",
        "\n",
        "    [f1, f2, f3, f4, f5] = levels\n",
        "\n",
        "    o = f5\n",
        "\n",
        "    # Decoder\n",
        "    o = (Conv2D(4096, (7 , 7 ), padding = 'same', kernel_initializer = 'he_normal', name = \"conv6\"))(o)\n",
        "    o = Activation('relu')(o)\n",
        "    o = Dropout(drop_rate)(o)\n",
        "    o = (Conv2D(4096, (1 , 1 ), padding = 'same', kernel_initializer = 'he_normal', name = \"conv7\"))(o)\n",
        "    o = Activation('relu')(o)\n",
        "    o = Dropout(drop_rate)(o)\n",
        "\n",
        "    o = (Conv2D(1, 1, padding='same', kernel_initializer='he_normal', name=\"scorer1\"))(o)\n",
        "    o = Conv2DTranspose(1, kernel_size=(64,64), padding='same', strides=(32,32), name=\"Upsample32\")(o)\n",
        "    o = (Conv2D(1, 1, padding='same', kernel_initializer='he_normal', name=\"output\"))(o)\n",
        "\n",
        "    # Output\n",
        "    o = Activation('sigmoid')(o)\n",
        "\n",
        "    model = Model(inputs, o)\n",
        "    model.compile(optimizer = adam_v2.Adam(learning_rate = lr), loss = binary_crossentropy, metrics = ['accuracy', 'mse'])\n",
        "    model.model_name = \"fcn_32\"\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNkFbGObEi-R"
      },
      "source": [
        "# Print model layers and number of parameters\n",
        "fcn_32().summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNscE1Pz3NTB"
      },
      "source": [
        "## Train on RGB feature data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45I0hjSxm6An"
      },
      "source": [
        "F = fcn_32(lr = 0.0001)\n",
        "save_model_fcn32 = ModelCheckpoint('fcn32-3d.hdf5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "train = trainGenerator(1, t_images, t_masks, data_gen_args, save_to_dir=None)\n",
        "F.fit(train, validation_data = validation_df, epochs=50, steps_per_epoch = 100, shuffle = True, callbacks=[save_model_fcn32])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KKMa6HBFK0i"
      },
      "source": [
        "# Save model history\n",
        "np.save('fcn32-3d-history.npy', F.history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu9fumpOqB4R"
      },
      "source": [
        "# Copy models to drive\n",
        "!cp fcn32-3d.hdf5 drive/MyDrive/Diss/\n",
        "!cp fcn32-3d-history.npy drive/MyDrive/Diss/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fsbck8aj3UQ6"
      },
      "source": [
        "## Train on 4-band data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSRcU7Y_3YJZ"
      },
      "source": [
        "### Train on 4-band Amazon data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBnvanCf3dom"
      },
      "source": [
        "F_4band = fcn_32(input_size=(512,512,4), lr = 0.0001)\n",
        "save_model_fcn_4band = ModelCheckpoint('fcn32-4d.hdf5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "F_4band.fit(train_df_4band_amazon, validation_data = validation_df_4band_amazon, epochs = 50, callbacks=[save_model_fcn_4band])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VH3Ic51Nswz"
      },
      "source": [
        "# Save model history\n",
        "np.save('fcn32-4d-history.npy', F_4band.history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAfV82jL5nOv"
      },
      "source": [
        "# Copy models to drive\n",
        "!cp fcn32-4d.hdf5 drive/MyDrive/Diss/\n",
        "!cp fcn32-4d-history.npy drive/MyDrive/Diss/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3cg4f5U3a0Q"
      },
      "source": [
        "### Train on 4-band Atlantic data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA5Do4LK3eSR"
      },
      "source": [
        "F_4band_atlantic = fcn_32(input_size=(512,512,4), lr = 0.0001)\n",
        "save_model_fcn32_4band_atlantic = ModelCheckpoint('fcn32-4d-atlantic.hdf5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "F_4band_atlantic.fit(train_df_4band_atlantic, validation_data = validation_df_4band_atlantic, epochs = 50, callbacks=[save_model_fcn32_4band_atlantic])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKGjlS7XNvcT"
      },
      "source": [
        "# Save model history\n",
        "np.save('fcn32-4d-atlantic-history.npy', F_4band_atlantic.history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5On0tO65pkc"
      },
      "source": [
        "# Copy models to drive\n",
        "!cp fcn32-4d-atlantic.hdf5 drive/MyDrive/Diss/\n",
        "!cp fcn32-4d-atlantic-history.npy drive/MyDrive/Diss/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-JXc78rQLaL"
      },
      "source": [
        "# Import Models and Compute Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTPCKtyBZej-"
      },
      "source": [
        "## RGB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6EorDk5QLaM"
      },
      "source": [
        "# Load 3-dim models and history stats\n",
        "attention_unet = load_model('unet-attention-3d.hdf5')\n",
        "unet = load_model('unet-3d.hdf5')\n",
        "\n",
        "unet_history = np.load('unet-3d-history.npy', allow_pickle='TRUE').item()\n",
        "attention_unet_history = np.load('unet-attention-3d-history.npy', allow_pickle='TRUE').item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwm2nd6mAJqa"
      },
      "source": [
        "# Plot accuracy and loss for U-Net\n",
        "\n",
        "## Accuracy\n",
        "plt.plot(unet_history['accuracy'])\n",
        "plt.plot(unet_history['val_accuracy'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "## Loss\n",
        "plt.plot(unet_history['loss'])\n",
        "plt.plot(unet_history['val_loss'])\n",
        "plt.ylabel('Loss', size=12)\n",
        "plt.xlabel('Epoch', size=12)\n",
        "plt.legend(['Training', 'Validation'], loc='lower right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTNTxObMBnEZ"
      },
      "source": [
        "# Plot accuracy and loss for Attention U-Net\n",
        "\n",
        "## Accuracy\n",
        "plt.plot(attention_unet_history['accuracy'])\n",
        "plt.plot(attention_unet_history['val_accuracy'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "## Loss\n",
        "plt.plot(attention_unet_history['loss'])\n",
        "plt.plot(attention_unet_history['val_loss'])\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JL_aqt5rQLaM"
      },
      "source": [
        "# Scores of each model\n",
        "unet_score = (score_eval(unet, validation_images, validation_masks))\n",
        "am_unet_score = (score_eval(attention_unet, validation_images, validation_masks))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xn_a9omPQLaM"
      },
      "source": [
        "# Precision and recall of each model\n",
        "unet_precision = (precision_eval(unet, validation_images, validation_masks))\n",
        "am_unet_precision = (precision_eval(attention_unet, validation_images, validation_masks))\n",
        "\n",
        "unet_recall = (recall_eval(unet, validation_images, validation_masks))\n",
        "am_unet_recall = (recall_eval(attention_unet, validation_images, validation_masks))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hj5HwfA1QLaM"
      },
      "source": [
        "# F1-scores of each model\n",
        "unet_f1_score = (f1_score_eval_basic(unet_precision, unet_recall))\n",
        "am_unet_f1_score = (f1_score_eval_basic(am_unet_precision, am_unet_recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wr93PcumQLaM"
      },
      "source": [
        "# Print score eval results for each model\n",
        "print('U-Net accuracy: ', np.mean(unet_score), np.std(unet_score))\n",
        "print('Attention U-Net accuracy: ', np.mean(am_unet_score), np.std(am_unet_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1021oSlAQLaN"
      },
      "source": [
        "# Print precision eval results for each model\n",
        "print('U-Net precision: ', np.mean(unet_precision), np.std(unet_precision))\n",
        "print('Attention U-Net precision: ', np.mean(am_unet_precision), np.std(am_unet_precision))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRGd9iNlQLaN"
      },
      "source": [
        "# Print recall eval results for each model\n",
        "print('U-Net recall: ', np.mean(unet_recall), np.std(unet_recall))\n",
        "print('Attention U-Net recall: ', np.mean(am_unet_recall), np.std(am_unet_recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFzHHEknQLaN"
      },
      "source": [
        "# Print f1-score eval results for each model\n",
        "print('U-Net F1-score: ', np.mean(unet_f1_score))\n",
        "print('Attention U-Net F1-score: ', np.mean(am_unet_f1_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JVLAuzIZhWv"
      },
      "source": [
        "## 4-band"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LI5RTFiZD9W-"
      },
      "source": [
        "### Amazon Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuWpNDuLZS2W"
      },
      "source": [
        "# Load 4-dim models and history stats\n",
        "attention_unet_4d = load_model('unet-attention-4d.hdf5')\n",
        "unet_4d = load_model('unet-4d.hdf5')\n",
        "\n",
        "unet_4d_history = np.load('unet-4d-history.npy', allow_pickle='TRUE').item()\n",
        "attention_unet_4d_history = np.load('unet-attention-4d-history.npy', allow_pickle='TRUE').item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwDcH3DJQLaO"
      },
      "source": [
        "# Plot accuracy and loss for U-Net\n",
        "\n",
        "## Accuracy\n",
        "plt.plot(unet_4d_history['accuracy'])\n",
        "plt.plot(unet_4d_history['val_accuracy'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "## Loss\n",
        "plt.plot(unet_4d_history['loss'])\n",
        "plt.plot(unet_4d_history['val_loss'])\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mcn0YjbZpPL"
      },
      "source": [
        "# Plot accuracy and loss for Attention U-Net\n",
        "\n",
        "## Accuracy\n",
        "plt.plot(attention_unet_4d_history['accuracy'])\n",
        "plt.plot(attention_unet_4d_history['val_accuracy'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "## Loss\n",
        "plt.plot(attention_unet_4d_history['loss'])\n",
        "plt.plot(attention_unet_4d_history['val_loss'])\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1V4qoM4ZtjE"
      },
      "source": [
        "# Scores of each model\n",
        "unet_4d_score = (score_eval2(unet_4d, validation_images2, validation_masks2))\n",
        "am_unet_4d_score = (score_eval2(attention_unet_4d, validation_images2, validation_masks2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVcI_yk4Z80x"
      },
      "source": [
        "# Precision and recall of each model\n",
        "unet_4d_precision = (precision_eval(unet_4d, validation_images2, validation_masks2))\n",
        "am_unet_4d_precision = (precision_eval(attention_unet_4d, validation_images2, validation_masks2))\n",
        "\n",
        "unet_4d_recall = (recall_eval(unet_4d, validation_images2, validation_masks2))\n",
        "am_unet_4d_recall = (recall_eval(attention_unet_4d, validation_images2, validation_masks2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvarhjO1aTX_"
      },
      "source": [
        "# F1-scores of each model\n",
        "unet_4d_f1_score = (f1_score_eval_basic(unet_4d_precision, unet_4d_recall))\n",
        "am_unet_4d_f1_score = (f1_score_eval_basic(am_unet_4d_precision, am_unet_4d_recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Htyl7Pi-aU88"
      },
      "source": [
        "# Print score eval results for each model\n",
        "print('U-Net accuracy: ', np.mean(unet_4d_score), np.std(unet_4d_score))\n",
        "print('Attention U-Net accuracy: ', np.mean(am_unet_4d_score), np.std(am_unet_4d_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geaOxWrpaWi9"
      },
      "source": [
        "# Print precision eval results for each model\n",
        "print('U-Net precision: ', np.mean(unet_4d_precision), np.std(unet_4d_precision))\n",
        "print('Attention U-Net precision: ', np.mean(am_unet_4d_precision), np.std(am_unet_4d_precision))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mpmu_7EaYEH"
      },
      "source": [
        "# Print recall eval results for each model\n",
        "print('U-Net recall: ', np.mean(unet_4d_recall), np.std(unet_4d_recall))\n",
        "print('Attention U-Net recall: ', np.mean(am_unet_4d_recall), np.std(am_unet_4d_recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0NXQpR2aYZG"
      },
      "source": [
        "# Print f1-score eval results for each model\n",
        "print('U-Net F1-score: ', np.mean(unet_4d_f1_score))\n",
        "print('Attention U-Net F1-score: ', np.mean(am_unet_4d_f1_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beZYrcZdzE0c"
      },
      "source": [
        "### Amazon on unseen Atlantic data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7LTlQvAzH8K"
      },
      "source": [
        "# Score\n",
        "unet_amazon_on_atlantic_score = score_eval2(unet_4d, validation_images3+test_images3, validation_masks3+test_masks3)\n",
        "am_unet_amazon_on_atlantic_score = score_eval2(attention_unet_4d, validation_images3+test_images3, validation_masks3+test_masks3)\n",
        "\n",
        "# Precision\n",
        "unet_amazon_on_atlantic_precision = (precision_eval(unet_4d, validation_images3+test_images3, validation_masks3+test_masks3))\n",
        "am_unet_amazon_on_atlantic_precision = (precision_eval(attention_unet_4d, validation_images3+test_images3, validation_masks3+test_masks3))\n",
        "\n",
        "# Recall\n",
        "unet_amazon_on_atlantic_recall = (recall_eval(unet_4d, validation_images3+test_images3, validation_masks3+test_masks3))\n",
        "am_unet_amazon_on_atlantic_recall = (recall_eval(attention_unet_4d, validation_images3+test_images3, validation_masks3+test_masks3))\n",
        "\n",
        "# F1-scores of each model\n",
        "unet_amazon_on_atlantic_f1_score = (f1_score_eval_basic(unet_amazon_on_atlantic_precision, unet_amazon_on_atlantic_recall))\n",
        "am_unet_amazon_on_atlantic_f1_score = (f1_score_eval_basic(am_unet_amazon_on_atlantic_precision, am_unet_amazon_on_atlantic_recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtAbkWSY0Xnn"
      },
      "source": [
        "# Print metrics\n",
        "print('U-Net score: ', np.mean(unet_amazon_on_atlantic_score), np.std(unet_amazon_on_atlantic_score))\n",
        "print('Attention U-Net score: ', np.mean(am_unet_amazon_on_atlantic_score), np.std(am_unet_amazon_on_atlantic_score))\n",
        "\n",
        "print('U-Net precision: ', np.mean(unet_amazon_on_atlantic_precision), np.std(unet_amazon_on_atlantic_precision))\n",
        "print('Attention U-Net precision: ', np.mean(am_unet_amazon_on_atlantic_precision), np.std(am_unet_amazon_on_atlantic_precision))\n",
        "\n",
        "print('U-Net recall: ', np.mean(unet_amazon_on_atlantic_recall), np.std(unet_amazon_on_atlantic_recall))\n",
        "print('Attention U-Net recall: ', np.mean(am_unet_amazon_on_atlantic_recall), np.std(am_unet_amazon_on_atlantic_recall))\n",
        "\n",
        "print('U-Net F1-score: ', unet_amazon_on_atlantic_f1_score)\n",
        "print('Attention U-Net F1-score: ', am_unet_amazon_on_atlantic_f1_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRQOG9uUECcu"
      },
      "source": [
        "### Atlantic Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQIc0XDmEFND"
      },
      "source": [
        "# Load 4-dim models and history stats\n",
        "attention_unet_4d_atlantic = load_model('unet-attention-4d-atlantic.hdf5')\n",
        "unet_4d_atlantic = load_model('unet-4d-atlantic.hdf5')\n",
        "\n",
        "unet_4d_atlantic_history = np.load('unet-4d-atlantic-history.npy', allow_pickle='TRUE').item()\n",
        "attention_unet_4d_atlantic_history = np.load('unet-attention-4d-atlantic-history.npy', allow_pickle='TRUE').item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4YBSQxjEWLc"
      },
      "source": [
        "# Plot accuracy and loss for U-Net\n",
        "\n",
        "## Accuracy\n",
        "plt.plot(unet_4d_atlantic_history['accuracy'])\n",
        "plt.plot(unet_4d_atlantic_history['val_accuracy'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "## Loss\n",
        "plt.plot(unet_4d_atlantic_history['loss'])\n",
        "plt.plot(unet_4d_atlantic_history['val_loss'])\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCFSJmMzEaR5"
      },
      "source": [
        "# Plot accuracy and loss for Attention U-Net\n",
        "\n",
        "## Accuracy\n",
        "plt.plot(attention_unet_4d_atlantic_history['accuracy'])\n",
        "plt.plot(attention_unet_4d_atlantic_history['val_accuracy'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "## Loss\n",
        "plt.plot(attention_unet_4d_atlantic_history['loss'])\n",
        "plt.plot(attention_unet_4d_atlantic_history['val_loss'])\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNxllVnXEhvb"
      },
      "source": [
        "# Scores of each model\n",
        "unet_4d_atlantic_score = (score_eval2(unet_4d_atlantic, validation_images3, validation_masks3))\n",
        "am_unet_4d_atlantic_score = (score_eval2(attention_unet_4d_atlantic, validation_images3, validation_masks3))\n",
        "\n",
        "# Precision and recall of each model\n",
        "unet_4d_atlantic_precision = (precision_eval(unet_4d_atlantic, validation_images3, validation_masks3))\n",
        "am_unet_4d_atlantic_precision = (precision_eval(attention_unet_4d_atlantic, validation_images3, validation_masks3))\n",
        "\n",
        "unet_4d_atlantic_recall = (recall_eval(unet_4d_atlantic, validation_images3, validation_masks3))\n",
        "am_unet_4d_atlantic_recall = (recall_eval(attention_unet_4d_atlantic, validation_images3, validation_masks3))\n",
        "\n",
        "# F1-scores of each model\n",
        "unet_4d_atlantic_f1_score = (f1_score_eval_basic(unet_4d_atlantic_precision, unet_4d_atlantic_recall))\n",
        "am_unet_4d_atlantic_f1_score = (f1_score_eval_basic(am_unet_4d_atlantic_precision, am_unet_4d_atlantic_recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuoQ8__mE9Ut"
      },
      "source": [
        "# Print metrics\n",
        "print('U-Net score: ', np.mean(unet_4d_atlantic_score), np.std(unet_4d_atlantic_score))\n",
        "print('Attention U-Net score: ', np.mean(am_unet_4d_atlantic_score), np.std(am_unet_4d_atlantic_score))\n",
        "\n",
        "print('U-Net precision: ', np.mean(unet_4d_atlantic_precision), np.std(unet_4d_atlantic_precision))\n",
        "print('Attention U-Net precision: ', np.mean(am_unet_4d_atlantic_precision), np.std(am_unet_4d_atlantic_precision))\n",
        "\n",
        "print('U-Net recall: ', np.mean(unet_4d_atlantic_recall), np.std(unet_4d_atlantic_recall))\n",
        "print('Attention U-Net recall: ', np.mean(am_unet_4d_atlantic_recall), np.std(am_unet_4d_atlantic_recall))\n",
        "\n",
        "print('U-Net F1-score: ', unet_4d_atlantic_f1_score)\n",
        "print('Attention U-Net F1-score: ', am_unet_4d_atlantic_f1_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LttV4BY-FO9Y"
      },
      "source": [
        "### Atlantic on unseen Amazon data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0mUcfs7FWCn"
      },
      "source": [
        "# Score\n",
        "unet_atlantic_on_amazon_score = score_eval2(unet_4d_atlantic, validation_images2+test_images2, validation_masks2+test_masks2)\n",
        "am_unet_atlantic_on_amazon_score = score_eval2(attention_unet_4d_atlantic, validation_images2+test_images2, validation_masks2+test_masks2)\n",
        "\n",
        "# Precision\n",
        "unet_atlantic_on_amazon_precision = (precision_eval(unet_4d_atlantic, validation_images2+test_images2, validation_masks2+test_masks2))\n",
        "am_unet_atlantic_on_amazon_precision = (precision_eval(attention_unet_4d_atlantic, validation_images2+test_images2, validation_masks2+test_masks2))\n",
        "\n",
        "# Recall\n",
        "unet_atlantic_on_amazon_recall = (recall_eval(unet_4d_atlantic, validation_images2+test_images2, validation_masks2+test_masks2))\n",
        "am_unet_atlantic_on_amazon_recall = (recall_eval(attention_unet_4d_atlantic, validation_images2+test_images2, validation_masks2+test_masks2))\n",
        "\n",
        "# F1-scores of each model\n",
        "unet_atlantic_on_amazon_f1_score = (f1_score_eval_basic(unet_atlantic_on_amazon_precision, unet_atlantic_on_amazon_recall))\n",
        "am_unet_atlantic_on_amazon_f1_score = (f1_score_eval_basic(am_unet_atlantic_on_amazon_precision, am_unet_atlantic_on_amazon_recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emaoDHfdFWfL"
      },
      "source": [
        "# Print metrics\n",
        "print('U-Net score: ', np.mean(unet_atlantic_on_amazon_score), np.std(unet_atlantic_on_amazon_score))\n",
        "print('Attention U-Net score: ', np.mean(am_unet_atlantic_on_amazon_score), np.std(am_unet_atlantic_on_amazon_score))\n",
        "\n",
        "print('U-Net precision: ', np.mean(unet_atlantic_on_amazon_precision), np.std(unet_atlantic_on_amazon_precision))\n",
        "print('Attention U-Net precision: ', np.mean(am_unet_atlantic_on_amazon_precision), np.std(am_unet_atlantic_on_amazon_precision))\n",
        "\n",
        "print('U-Net recall: ', np.mean(unet_atlantic_on_amazon_recall), np.std(unet_atlantic_on_amazon_recall))\n",
        "print('Attention U-Net recall: ', np.mean(am_unet_atlantic_on_amazon_recall), np.std(am_unet_atlantic_on_amazon_recall))\n",
        "\n",
        "print('U-Net F1-score: ', unet_atlantic_on_amazon_f1_score)\n",
        "print('Attention U-Net F1-score: ', am_unet_atlantic_on_amazon_f1_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EWGiqFzlsrv"
      },
      "source": [
        "### Amazon and Atlantic unseen test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Txs1Av6GpAlu"
      },
      "source": [
        "# Amazon trained model on Amazon test data\n",
        "# Scores of each model\n",
        "unet_4d_score_test = (score_eval2(unet_4d, test_images2, test_masks2))\n",
        "am_unet_4d_score_test = (score_eval2(attention_unet_4d, test_images2, test_masks2))\n",
        "\n",
        "# Precision and recall of each model\n",
        "unet_4d_precision_test = (precision_eval(unet_4d, test_images2, test_masks2))\n",
        "am_unet_4d_precision_test = (precision_eval(attention_unet_4d, test_images2, test_masks2))\n",
        "\n",
        "unet_4d_recall_test = (recall_eval(unet_4d, test_images2, test_masks2))\n",
        "am_unet_4d_recall_test = (recall_eval(attention_unet_4d, test_images2, test_masks2))\n",
        "\n",
        "# F1-scores of each model\n",
        "unet_4d_f1_score_test = (f1_score_eval_basic(unet_4d_precision_test, unet_4d_recall_test))\n",
        "am_unet_4d_f1_score_test = (f1_score_eval_basic(am_unet_4d_precision_test, am_unet_4d_recall_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Njk-zCC7lw8_"
      },
      "source": [
        "# Atlantic trained model on Atlantic test data\n",
        "# Scores of each model\n",
        "unet_4d_atlantic_score_test = (score_eval2(unet_4d_atlantic, test_images3, test_masks3))\n",
        "am_unet_4d_atlantic_score_test = (score_eval2(attention_unet_4d_atlantic, test_images3, test_masks3))\n",
        "\n",
        "# Precision and recall of each model\n",
        "unet_4d_atlantic_precision_test = (precision_eval(unet_4d_atlantic, test_images3, test_masks3))\n",
        "am_unet_4d_atlantic_precision_test = (precision_eval(attention_unet_4d_atlantic, test_images3, test_masks3))\n",
        "\n",
        "unet_4d_atlantic_recall_test = (recall_eval(unet_4d_atlantic, test_images3, test_masks3))\n",
        "am_unet_4d_atlantic_recall_test = (recall_eval(attention_unet_4d_atlantic, test_images3, test_masks3))\n",
        "\n",
        "# F1-scores of each model\n",
        "unet_4d_atlantic_f1_score_test = (f1_score_eval_basic(unet_4d_atlantic_precision_test, unet_4d_atlantic_recall_test))\n",
        "am_unet_4d_atlantic_f1_score_test = (f1_score_eval_basic(am_unet_4d_atlantic_precision_test, am_unet_4d_atlantic_recall_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSCJGrpkppSA"
      },
      "source": [
        "# Print metrics for Amazon on Amazon Test set\n",
        "print('U-Net score: ', np.mean(unet_4d_score_test), np.std(unet_4d_score_test))\n",
        "print('Attention U-Net score: ', np.mean(am_unet_4d_score_test), np.std(am_unet_4d_score_test))\n",
        "\n",
        "print('U-Net precision: ', np.mean(unet_4d_precision_test), np.std(unet_4d_precision_test))\n",
        "print('Attention U-Net precision: ', np.mean(am_unet_4d_precision_test), np.std(am_unet_4d_precision_test))\n",
        "\n",
        "print('U-Net recall: ', np.mean(unet_4d_recall_test), np.std(unet_4d_recall_test))\n",
        "print('Attention U-Net recall: ', np.mean(am_unet_4d_recall_test), np.std(am_unet_4d_recall_test))\n",
        "\n",
        "print('U-Net F1-score: ', unet_4d_f1_score_test)\n",
        "print('Attention U-Net F1-score: ', am_unet_4d_f1_score_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnXkLvzuqpYv"
      },
      "source": [
        "# Print metrics for Atlantic on Atlantic Test set\n",
        "print('U-Net score: ', np.mean(unet_4d_atlantic_score_test), np.std(unet_4d_atlantic_score_test))\n",
        "print('Attention U-Net score: ', np.mean(am_unet_4d_atlantic_score_test), np.std(am_unet_4d_atlantic_score_test))\n",
        "\n",
        "print('U-Net precision: ', np.mean(unet_4d_atlantic_precision_test), np.std(unet_4d_atlantic_precision_test))\n",
        "print('Attention U-Net precision: ', np.mean(am_unet_4d_atlantic_precision_test), np.std(am_unet_4d_atlantic_precision_test))\n",
        "\n",
        "print('U-Net recall: ', np.mean(unet_4d_atlantic_recall_test), np.std(unet_4d_atlantic_recall_test))\n",
        "print('Attention U-Net recall: ', np.mean(am_unet_4d_atlantic_recall_test), np.std(am_unet_4d_atlantic_recall_test))\n",
        "\n",
        "print('U-Net F1-score: ', unet_4d_atlantic_f1_score_test)\n",
        "print('Attention U-Net F1-score: ', am_unet_4d_atlantic_f1_score_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsvOhqlr8d2V"
      },
      "source": [
        "## ResNet50-SegNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PenYqdMW8frD"
      },
      "source": [
        "# Load ResNet models and history stats\n",
        "resnet_3d = ResNet50SegNet()\n",
        "resnet_3d.load_weights('resnet50segnet-3d.hdf5')\n",
        "resnet_4d_amazon = ResNet50SegNet(input_size=(512,512,4))\n",
        "resnet_4d_amazon.load_weights('resnet50segnet-4d.hdf5')\n",
        "resnet_4d_atlantic = ResNet50SegNet(input_size=(512,512,4))\n",
        "resnet_4d_atlantic.load_weights('resnet50segnet-4d-atlantic.hdf5')\n",
        "\n",
        "resnet_3d_history = np.load('resnet50segnet-3d-history.npy', allow_pickle='TRUE').item()\n",
        "resnet50segnet_4d_amazon_history = np.load('resnet50segnet-4d-history.npy', allow_pickle='TRUE').item()\n",
        "resnet50segnet_4d_atlantic_history = np.load('resnet50segnet-4d-history-atlantic.npy', allow_pickle='TRUE').item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MywXNxy490t6"
      },
      "source": [
        "# Metrics of each model on respective datasets\n",
        "\n",
        "# Score\n",
        "resnet_3d_score = (score_eval(resnet_3d, validation_images, validation_masks))\n",
        "resnet_4d_amazon_score = (score_eval2(resnet_4d_amazon, validation_images2, validation_masks2))\n",
        "resnet_4d_atlantic_score = (score_eval2(resnet_4d_atlantic, validation_images3, validation_masks3))\n",
        "\n",
        "# Precision and recall\n",
        "resnet_3d_precision = (precision_eval(resnet_3d, validation_images, validation_masks))\n",
        "resnet_4d_amazon_precision = (precision_eval(resnet_4d_amazon, validation_images2, validation_masks2))\n",
        "resnet_4d_atlantic_precision = (precision_eval(resnet_4d_atlantic, validation_images3, validation_masks3))\n",
        "\n",
        "resnet_3d_recall = (recall_eval(resnet_3d, validation_images, validation_masks))\n",
        "resnet_4d_amazon_recall = (recall_eval(resnet_4d_amazon, validation_images2, validation_masks2))\n",
        "resnet_4d_atlantic_recall = (recall_eval(resnet_4d_atlantic, validation_images3, validation_masks3))\n",
        "\n",
        "# F1-score\n",
        "resnet_3d_f1_score = (f1_score_eval_basic(resnet_3d_precision, resnet_3d_recall))\n",
        "resnet_4d_amazon_f1_score = (f1_score_eval_basic(resnet_4d_amazon_precision, resnet_4d_amazon_recall))\n",
        "resnet_4d_atlantic_f1_score = (f1_score_eval_basic(resnet_4d_atlantic_precision, resnet_4d_atlantic_recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJUCREQf--Vm"
      },
      "source": [
        "# Metrics of 4-dim Amazon trained model on Atlantic data and vice versa\n",
        "\n",
        "# Score\n",
        "resnet_4d_amazon_on_atlantic_score = (score_eval2(resnet_4d_amazon, validation_images3+test_images3, validation_masks3+test_masks3))\n",
        "resnet_4d_atlantic_on_amazon_score = (score_eval2(resnet_4d_atlantic, validation_images2+test_images2, validation_masks2+test_masks2))\n",
        "\n",
        "# Precision and recall\n",
        "resnet_4d_amazon_on_atlantic_precision = (precision_eval(resnet_4d_amazon, validation_images3+test_images3, validation_masks3+test_masks3))\n",
        "resnet_4d_atlantic_on_amazon_precision = (precision_eval(resnet_4d_atlantic, validation_images2+test_images2, validation_masks2+test_masks2))\n",
        "\n",
        "resnet_4d_amazon_on_atlantic_recall = (recall_eval(resnet_4d_amazon, validation_images3+test_images3, validation_masks3+test_masks3))\n",
        "resnet_4d_atlantic_on_amazon_recall = (recall_eval(resnet_4d_atlantic, validation_images2+test_images2, validation_masks2+test_masks2))\n",
        "\n",
        "# F1-score\n",
        "resnet_4d_amazon_on_atlantic_f1_score = (f1_score_eval_basic(resnet_4d_amazon_on_atlantic_precision, resnet_4d_amazon_on_atlantic_recall))\n",
        "resnet_4d_atlantic_on_amazon_f1_score = (f1_score_eval_basic(resnet_4d_atlantic_on_amazon_precision, resnet_4d_atlantic_on_amazon_recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngUhJxj7_xWf"
      },
      "source": [
        "# Print metrics\n",
        "print('Accuracy | Precision | Recall | F1-score')\n",
        "print('ResNet 3-dim: ', np.mean(resnet_3d_score), np.mean(resnet_3d_precision), np.mean(resnet_3d_recall), resnet_3d_f1_score)\n",
        "print('ResNet 3-dim: ', np.std(resnet_3d_score), np.std(resnet_3d_precision), np.std(resnet_3d_recall), resnet_3d_f1_score)\n",
        "print('----')\n",
        "print('ResNet 4-dim Amazon: ', np.mean(resnet_4d_amazon_score), np.mean(resnet_4d_amazon_precision), np.mean(resnet_4d_amazon_recall), resnet_4d_amazon_f1_score)\n",
        "print('ResNet 4-dim Amazon: ', np.std(resnet_4d_amazon_score), np.std(resnet_4d_amazon_precision), np.std(resnet_4d_amazon_recall), resnet_4d_amazon_f1_score)\n",
        "print('----')\n",
        "print('ResNet 4-dim Atlantic: ', np.mean(resnet_4d_atlantic_score), np.mean(resnet_4d_atlantic_precision), np.mean(resnet_4d_atlantic_recall), resnet_4d_atlantic_f1_score)\n",
        "print('ResNet 4-dim Atlantic: ', np.std(resnet_4d_atlantic_score), np.std(resnet_4d_atlantic_precision), np.std(resnet_4d_atlantic_recall), resnet_4d_atlantic_f1_score)\n",
        "print('----')\n",
        "print('ResNet 4-dim Amazon on Atlantic: ', np.mean(resnet_4d_amazon_on_atlantic_score), np.mean(resnet_4d_amazon_on_atlantic_precision), np.mean(resnet_4d_amazon_on_atlantic_recall), resnet_4d_amazon_on_atlantic_f1_score)\n",
        "print('ResNet 4-dim Amazon on Atlantic: ', np.std(resnet_4d_amazon_on_atlantic_score), np.std(resnet_4d_amazon_on_atlantic_precision), np.std(resnet_4d_amazon_on_atlantic_recall), resnet_4d_amazon_on_atlantic_f1_score)\n",
        "print('----')\n",
        "print('ResNet 4-dim Atlantic on Amazon: ', np.mean(resnet_4d_atlantic_on_amazon_score), np.mean(resnet_4d_atlantic_on_amazon_precision), np.mean(resnet_4d_atlantic_on_amazon_recall), resnet_4d_atlantic_on_amazon_f1_score)\n",
        "print('ResNet 4-dim Atlantic on Amazon: ', np.std(resnet_4d_atlantic_on_amazon_score), np.std(resnet_4d_atlantic_on_amazon_precision), np.std(resnet_4d_atlantic_on_amazon_recall), resnet_4d_atlantic_on_amazon_f1_score)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTWUmNO0lzYn"
      },
      "source": [
        "### Amazon and Atlantic unseen test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrWEhFiql0l3"
      },
      "source": [
        "# Amazon trained model on Amazon test data\n",
        "# Scores of each model\n",
        "resnet_4d_score_test = (score_eval2(resnet_4d_amazon, test_images2, test_masks2))\n",
        "\n",
        "# Precision and recall of each model\n",
        "resnet_4d_precision_test = (precision_eval(resnet_4d_amazon, test_images2, test_masks2))\n",
        "resnet_4d_recall_test = (recall_eval(resnet_4d_amazon, test_images2, test_masks2))\n",
        "\n",
        "# F1-scores of each model\n",
        "resnet_4d_f1_score_test = (f1_score_eval_basic(resnet_4d_precision_test, resnet_4d_recall_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_UxTzoPrI1p"
      },
      "source": [
        "# Atlantic trained model on Atlantic test data\n",
        "# Scores of each model\n",
        "resnet_4d_atlantic_score_test = (score_eval2(resnet_4d_atlantic, test_images3, test_masks3))\n",
        "\n",
        "# Precision and recall of each model\n",
        "resnet_4d_atlantic_precision_test = (precision_eval(resnet_4d_atlantic, test_images3, test_masks3))\n",
        "resnet_4d_atlantic_recall_test = (recall_eval(resnet_4d_atlantic, test_images3, test_masks3))\n",
        "\n",
        "# F1-scores of each model\n",
        "resnet_4d_atlantic_f1_score_test = (f1_score_eval_basic(resnet_4d_atlantic_precision_test, resnet_4d_atlantic_recall_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye2nYpk6rKgz"
      },
      "source": [
        "# Print metrics for Amazon on Amazon Test set\n",
        "print('ResNet score: ', np.mean(resnet_4d_score_test), np.std(resnet_4d_score_test))\n",
        "print('ResNet precision: ', np.mean(resnet_4d_precision_test), np.std(resnet_4d_precision_test))\n",
        "print('ResNet recall: ', np.mean(resnet_4d_recall_test), np.std(resnet_4d_recall_test))\n",
        "print('ResNet F1-score: ', resnet_4d_f1_score_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65sr0IQcrMbZ"
      },
      "source": [
        "# Print metrics for Atlantic on Atlantic Test set\n",
        "print('ResNet score: ', np.mean(resnet_4d_atlantic_score_test), np.std(resnet_4d_atlantic_score_test))\n",
        "print('ResNet precision: ', np.mean(resnet_4d_atlantic_precision_test), np.std(resnet_4d_atlantic_precision_test))\n",
        "print('ResNet recall: ', np.mean(resnet_4d_atlantic_recall_test), np.std(resnet_4d_atlantic_recall_test))\n",
        "print('ResNet F1-score: ', resnet_4d_atlantic_f1_score_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f__KAFLHL7Nw"
      },
      "source": [
        "## FCN32-VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyHLMDbHL8-u"
      },
      "source": [
        "# Import models\n",
        "fcn32_3d = load_model('fcn32-3d.hdf5')\n",
        "fcn32_4d_amazon = load_model('fcn32-4d.hdf5')\n",
        "fcn32_4d_atlantic = load_model('fcn32-4d-atlantic.hdf5')\n",
        "\n",
        "fcn32_3d_history = np.load('fcn32-3d-history.npy', allow_pickle='TRUE').item()\n",
        "fcn32_4d_amazon_history = np.load('fcn32-4d-history.npy', allow_pickle='TRUE').item()\n",
        "fcn32_4d_atlantic_history = np.load('fcn32-4d-atlantic-history.npy', allow_pickle='TRUE').item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE6pvNzUM6Qj"
      },
      "source": [
        "# Metrics of each model on respective datasets\n",
        "\n",
        "# Score\n",
        "fcn32_3d_score = (score_eval(fcn32_3d, validation_images, validation_masks))\n",
        "fcn32_4d_amazon_score = (score_eval2(fcn32_4d_amazon, validation_images2, validation_masks2))\n",
        "fcn32_4d_atlantic_score = (score_eval2(fcn32_4d_atlantic, validation_images3, validation_masks3))\n",
        "\n",
        "# Precision and recall\n",
        "fcn32_3d_precision = (precision_eval(fcn32_3d, validation_images, validation_masks))\n",
        "fcn32_4d_amazon_precision = (precision_eval(fcn32_4d_amazon, validation_images2, validation_masks2))\n",
        "fcn32_4d_atlantic_precision = (precision_eval(fcn32_4d_atlantic, validation_images3, validation_masks3))\n",
        "\n",
        "fcn32_3d_recall = (recall_eval(fcn32_3d, validation_images, validation_masks))\n",
        "fcn32_4d_amazon_recall = (recall_eval(fcn32_4d_amazon, validation_images2, validation_masks2))\n",
        "fcn32_4d_atlantic_recall = (recall_eval(fcn32_4d_atlantic, validation_images3, validation_masks3))\n",
        "\n",
        "# F1-score\n",
        "fcn32_3d_f1_score = (f1_score_eval_basic(fcn32_3d_precision, fcn32_3d_recall))\n",
        "fcn32_4d_amazon_f1_score = (f1_score_eval_basic(fcn32_4d_amazon_precision, fcn32_4d_amazon_recall))\n",
        "fcn32_4d_atlantic_f1_score = (f1_score_eval_basic(fcn32_4d_atlantic_precision, fcn32_4d_atlantic_recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx2ymcR3NLP_"
      },
      "source": [
        "# Metrics of 4-dim Amazon trained model on Atlantic data and vice versa\n",
        "\n",
        "# Score\n",
        "fcn32_4d_amazon_on_atlantic_score = (score_eval2(fcn32_4d_amazon, validation_images3+test_images3, validation_masks3+test_masks3))\n",
        "fcn32_4d_atlantic_on_amazon_score = (score_eval2(fcn32_4d_atlantic, validation_images2+test_images2, validation_masks2+test_masks2))\n",
        "\n",
        "# Precision and recall\n",
        "fcn32_4d_amazon_on_atlantic_precision = (precision_eval(fcn32_4d_amazon, validation_images3+test_images3, validation_masks3+test_masks3))\n",
        "fcn32_4d_atlantic_on_amazon_precision = (precision_eval(fcn32_4d_atlantic, validation_images2+test_images2, validation_masks2+test_masks2))\n",
        "\n",
        "fcn32_4d_amazon_on_atlantic_recall = (recall_eval(fcn32_4d_amazon, validation_images3+test_images3, validation_masks3+test_masks3))\n",
        "fcn32_4d_atlantic_on_amazon_recall = (recall_eval(fcn32_4d_atlantic, validation_images2+test_images2, validation_masks2+test_masks2))\n",
        "\n",
        "# F1-score\n",
        "fcn32_4d_amazon_on_atlantic_f1_score = (f1_score_eval_basic(fcn32_4d_amazon_on_atlantic_precision, fcn32_4d_amazon_on_atlantic_recall))\n",
        "fcn32_4d_atlantic_on_amazon_f1_score = (f1_score_eval_basic(fcn32_4d_atlantic_on_amazon_precision, fcn32_4d_atlantic_on_amazon_recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXe9ph53NXIb"
      },
      "source": [
        "# Print metrics\n",
        "print('Accuracy | Precision | Recall | F1-score')\n",
        "print('FCN32 3-dim: ', np.mean(fcn32_3d_score), np.mean(fcn32_3d_precision), np.mean(fcn32_3d_recall), fcn32_3d_f1_score)\n",
        "print('FCN32 3-dim: ', np.std(fcn32_3d_score), np.std(fcn32_3d_precision), np.std(fcn32_3d_recall), fcn32_3d_f1_score)\n",
        "print('----')\n",
        "print('FCN32 4-dim Amazon: ', np.mean(fcn32_4d_amazon_score), np.mean(fcn32_4d_amazon_precision), np.mean(fcn32_4d_amazon_recall), fcn32_4d_amazon_f1_score)\n",
        "print('FCN32 4-dim Amazon: ', np.std(fcn32_4d_amazon_score), np.std(fcn32_4d_amazon_precision), np.std(fcn32_4d_amazon_recall), fcn32_4d_amazon_f1_score)\n",
        "print('----')\n",
        "print('FCN32 4-dim Atlantic: ', np.mean(fcn32_4d_atlantic_score), np.mean(fcn32_4d_atlantic_precision), np.mean(fcn32_4d_atlantic_recall), fcn32_4d_atlantic_f1_score)\n",
        "print('FCN32 4-dim Atlantic: ', np.std(fcn32_4d_atlantic_score), np.std(fcn32_4d_atlantic_precision), np.std(fcn32_4d_atlantic_recall), fcn32_4d_atlantic_f1_score)\n",
        "print('----')\n",
        "print('FCN32 4-dim Amazon on Atlantic: ', np.mean(fcn32_4d_amazon_on_atlantic_score), np.mean(fcn32_4d_amazon_on_atlantic_precision), np.mean(fcn32_4d_amazon_on_atlantic_recall), fcn32_4d_amazon_on_atlantic_f1_score)\n",
        "print('FCN32 4-dim Amazon on Atlantic: ', np.std(fcn32_4d_amazon_on_atlantic_score), np.std(fcn32_4d_amazon_on_atlantic_precision), np.std(fcn32_4d_amazon_on_atlantic_recall), fcn32_4d_amazon_on_atlantic_f1_score)\n",
        "print('----')\n",
        "print('FCN32 4-dim Atlantic on Amazon: ', np.mean(fcn32_4d_atlantic_on_amazon_score), np.mean(fcn32_4d_atlantic_on_amazon_precision), np.mean(fcn32_4d_atlantic_on_amazon_recall), fcn32_4d_atlantic_on_amazon_f1_score)\n",
        "print('FCN32 4-dim Atlantic on Amazon: ', np.std(fcn32_4d_atlantic_on_amazon_score), np.std(fcn32_4d_atlantic_on_amazon_precision), np.std(fcn32_4d_atlantic_on_amazon_recall), fcn32_4d_atlantic_on_amazon_f1_score)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XExXvTaUl1hH"
      },
      "source": [
        "### Amazon and Atlantic unseen test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouL1rrHSl2RH"
      },
      "source": [
        "# Amazon trained model on Amazon test data\n",
        "# Scores of each model\n",
        "fcn32_4d_score_test = (score_eval2(fcn32_4d_amazon, test_images2, test_masks2))\n",
        "\n",
        "# Precision and recall of each model\n",
        "fcn32_4d_precision_test = (precision_eval(fcn32_4d_amazon, test_images2, test_masks2))\n",
        "fcn32_4d_recall_test = (recall_eval(fcn32_4d_amazon, test_images2, test_masks2))\n",
        "\n",
        "# F1-scores of each model\n",
        "fcn32_4d_f1_score_test = (f1_score_eval_basic(fcn32_4d_precision_test, fcn32_4d_recall_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBvV64WrsVrT"
      },
      "source": [
        "# Atlantic trained model on Atlantic test data\n",
        "# Scores of each model\n",
        "fcn32_4d_atlantic_score_test = (score_eval2(fcn32_4d_atlantic, test_images3, test_masks3))\n",
        "\n",
        "# Precision and recall of each model\n",
        "fcn32_4d_atlantic_precision_test = (precision_eval(fcn32_4d_atlantic, test_images3, test_masks3))\n",
        "fcn32_4d_atlantic_recall_test = (recall_eval(fcn32_4d_atlantic, test_images3, test_masks3))\n",
        "\n",
        "# F1-scores of each model\n",
        "fcn32_4d_atlantic_f1_score_test = (f1_score_eval_basic(fcn32_4d_atlantic_precision_test, fcn32_4d_atlantic_recall_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq8c0dsQsXQs"
      },
      "source": [
        "# Print metrics for Amazon on Amazon Test set\n",
        "print('FCN32 score: ', np.mean(fcn32_4d_score_test), np.std(fcn32_4d_score_test))\n",
        "print('FCN32 precision: ', np.mean(fcn32_4d_precision_test), np.std(fcn32_4d_precision_test))\n",
        "print('FCN32 recall: ', np.mean(fcn32_4d_recall_test), np.std(fcn32_4d_recall_test))\n",
        "print('FCN32 F1-score: ', fcn32_4d_f1_score_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu8TMJWRsZAg"
      },
      "source": [
        "# Print metrics for Atlantic on Atlantic Test set\n",
        "print('FCN32 score: ', np.mean(fcn32_4d_atlantic_score_test), np.std(fcn32_4d_atlantic_score_test))\n",
        "print('FCN32 precision: ', np.mean(fcn32_4d_atlantic_precision_test), np.std(fcn32_4d_atlantic_precision_test))\n",
        "print('FCN32 recall: ', np.mean(fcn32_4d_atlantic_recall_test), np.std(fcn32_4d_atlantic_recall_test))\n",
        "print('FCN32 F1-score: ', fcn32_4d_atlantic_f1_score_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PIo2l0n1XOt"
      },
      "source": [
        "# Produce metric datasets for export"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1rZvCii11wn"
      },
      "source": [
        "## RGB data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yTM5am91bWO"
      },
      "source": [
        "scores_3d = [unet_score, am_unet_score, resnet_3d_score, fcn32_3d_score]\n",
        "precision_3d = [unet_precision, am_unet_precision, resnet_3d_precision, fcn32_3d_precision]\n",
        "recall_3d = [unet_recall, am_unet_recall, resnet_3d_recall, fcn32_3d_recall]\n",
        "f1_scores_3d = [unet_f1_score, am_unet_f1_score, resnet_3d_f1_score, fcn32_3d_f1_score]\n",
        "\n",
        "import pandas as pd\n",
        "metrics_3d = {'classifier': ['U-Net', 'Attention U-Net', 'ResNet50-SegNet', 'FCN32-VGG16'],\n",
        "              'accuracy': [np.mean(n) for n in scores_3d],\n",
        "              'precision': [np.mean(n) for n in precision_3d],\n",
        "              'recall': [np.mean(n) for n in recall_3d],\n",
        "              'f1_score': [np.mean(n) for n in f1_scores_3d],\n",
        "              'accuracy_std': [np.std(n) for n in scores_3d],\n",
        "              'precision_std': [np.std(n) for n in precision_3d],\n",
        "              'recall_std': [np.std(n) for n in recall_3d]\n",
        "              }\n",
        "metrics_3d = pd.DataFrame(metrics_3d)\n",
        "metrics_3d.to_csv('metrics_3d.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hj2L_RE7149Q"
      },
      "source": [
        "## 4-band Amazon data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMbXcGo31682"
      },
      "source": [
        "scores_4d = [unet_4d_score, am_unet_4d_score, resnet_4d_amazon_score, fcn32_4d_amazon_score]\n",
        "precision_4d = [unet_4d_precision, am_unet_4d_precision, resnet_4d_amazon_precision, fcn32_4d_amazon_precision]\n",
        "recall_4d = [unet_4d_recall, am_unet_4d_recall, resnet_4d_amazon_recall, fcn32_4d_amazon_recall]\n",
        "f1_scores_4d = [unet_4d_f1_score, am_unet_4d_f1_score, resnet_4d_amazon_f1_score, fcn32_4d_amazon_f1_score]\n",
        "\n",
        "metrics_4d = {'classifier': ['U-Net', 'Attention U-Net', 'ResNet50-SegNet', 'FCN32-VGG16'],\n",
        "              'accuracy': [np.mean(n) for n in scores_4d],\n",
        "              'precision': [np.mean(n) for n in precision_4d],\n",
        "              'recall': [np.mean(n) for n in recall_4d],\n",
        "              'f1_score': [np.mean(n) for n in f1_scores_4d],\n",
        "              'accuracy_std': [np.std(n) for n in scores_4d],\n",
        "              'precision_std': [np.std(n) for n in precision_4d],\n",
        "              'recall_std': [np.std(n) for n in recall_4d]\n",
        "              }\n",
        "metrics_4d = pd.DataFrame(metrics_4d)\n",
        "metrics_4d.to_csv('metrics_4d_amazon.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eYZ0RkN17XE"
      },
      "source": [
        "## 4-band Atlantic Forest data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edIeklLV19Zi"
      },
      "source": [
        "scores_4d_atl = [unet_4d_atlantic_score, am_unet_4d_atlantic_score, resnet_4d_atlantic_score, fcn32_4d_atlantic_score]\n",
        "precision_4d_atl = [unet_4d_atlantic_precision, am_unet_4d_atlantic_precision, resnet_4d_atlantic_precision, fcn32_4d_atlantic_precision]\n",
        "recall_4d_atl = [unet_4d_atlantic_recall, am_unet_4d_atlantic_recall, resnet_4d_atlantic_recall, fcn32_4d_atlantic_recall]\n",
        "f1_scores_4d_atl = [unet_4d_atlantic_f1_score, am_unet_4d_atlantic_f1_score, resnet_4d_atlantic_f1_score, fcn32_4d_atlantic_f1_score]\n",
        "\n",
        "metrics_4d_atl = {'classifier': ['U-Net', 'Attention U-Net', 'ResNet50-SegNet', 'FCN32-VGG16'],\n",
        "              'accuracy': [np.mean(n) for n in scores_4d_atl],\n",
        "              'precision': [np.mean(n) for n in precision_4d_atl],\n",
        "              'recall': [np.mean(n) for n in recall_4d_atl],\n",
        "              'f1_score': [np.mean(n) for n in f1_scores_4d_atl],\n",
        "              'accuracy_std': [np.std(n) for n in scores_4d_atl],\n",
        "              'precision_std': [np.std(n) for n in precision_4d_atl],\n",
        "              'recall_std': [np.std(n) for n in recall_4d_atl]\n",
        "              }\n",
        "metrics_4d_atl = pd.DataFrame(metrics_4d_atl)\n",
        "metrics_4d_atl.to_csv('metrics_4d_atlantic_forest.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tF7HQghy5Qxz"
      },
      "source": [
        "## Test set data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCt9VZ3s5SSr"
      },
      "source": [
        "scores_4d_test = [unet_4d_score_test, am_unet_4d_score_test, resnet_4d_score_test, fcn32_4d_score_test]\n",
        "precision_4d_test = [unet_4d_precision_test, am_unet_4d_precision_test, resnet_4d_precision_test, fcn32_4d_precision_test]\n",
        "recall_4d_test = [unet_4d_recall_test, am_unet_4d_recall_test, resnet_4d_recall_test, fcn32_4d_recall_test]\n",
        "f1_scores_4d_test = [unet_4d_f1_score_test, am_unet_4d_f1_score_test, resnet_4d_f1_score_test, fcn32_4d_f1_score_test]\n",
        "\n",
        "metrics_4d_test = {'classifier': ['U-Net', 'Attention U-Net', 'ResNet50-SegNet', 'FCN32-VGG16'],\n",
        "              'accuracy': [np.mean(n) for n in scores_4d_test],\n",
        "              'precision': [np.mean(n) for n in precision_4d_test],\n",
        "              'recall': [np.mean(n) for n in recall_4d_test],\n",
        "              'f1_score': [np.mean(n) for n in f1_scores_4d_test],\n",
        "              'accuracy_std': [np.std(n) for n in scores_4d_test],\n",
        "              'precision_std': [np.std(n) for n in precision_4d_test],\n",
        "              'recall_std': [np.std(n) for n in recall_4d_test]\n",
        "              }\n",
        "metrics_4d_test = pd.DataFrame(metrics_4d_test)\n",
        "metrics_4d_test.to_csv('metrics_4d_amazon_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M127Qw5A5xUX"
      },
      "source": [
        "scores_4d_atl_test = [unet_4d_atlantic_score_test, am_unet_4d_atlantic_score_test, resnet_4d_atlantic_score_test, fcn32_4d_atlantic_score_test]\n",
        "precision_4d_atl_test = [unet_4d_atlantic_precision_test, am_unet_4d_atlantic_precision_test, resnet_4d_atlantic_precision_test, fcn32_4d_atlantic_precision_test]\n",
        "recall_4d_atl_test = [unet_4d_atlantic_recall_test, am_unet_4d_atlantic_recall_test, resnet_4d_atlantic_recall_test, fcn32_4d_atlantic_recall_test]\n",
        "f1_scores_4d_atl_test = [unet_4d_atlantic_f1_score_test, am_unet_4d_atlantic_f1_score_test, resnet_4d_atlantic_f1_score_test, fcn32_4d_atlantic_f1_score_test]\n",
        "\n",
        "metrics_4d_atl_test = {'classifier': ['U-Net', 'Attention U-Net', 'ResNet50-SegNet', 'FCN32-VGG16'],\n",
        "              'accuracy': [np.mean(n) for n in scores_4d_atl_test],\n",
        "              'precision': [np.mean(n) for n in precision_4d_atl_test],\n",
        "              'recall': [np.mean(n) for n in recall_4d_atl_test],\n",
        "              'f1_score': [np.mean(n) for n in f1_scores_4d_atl_test],\n",
        "              'accuracy_std': [np.std(n) for n in scores_4d_atl_test],\n",
        "              'precision_std': [np.std(n) for n in precision_4d_atl_test],\n",
        "              'recall_std': [np.std(n) for n in recall_4d_atl_test]\n",
        "              }\n",
        "metrics_4d_atl_test = pd.DataFrame(metrics_4d_atl_test)\n",
        "metrics_4d_atl_test.to_csv('metrics_4d_atlantic_forest_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYkobMR86TR6"
      },
      "source": [
        "## Testing on opposite dataset (e.g. train on Amazon, test on Atlantic)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYz22lx-6X3V"
      },
      "source": [
        "scores_amazon_on_atlantic = [unet_amazon_on_atlantic_score, am_unet_amazon_on_atlantic_score, resnet_4d_amazon_on_atlantic_score, fcn32_4d_amazon_on_atlantic_score]\n",
        "precision_amazon_on_atlantic = [unet_amazon_on_atlantic_precision, am_unet_amazon_on_atlantic_precision, resnet_4d_amazon_on_atlantic_precision, fcn32_4d_amazon_on_atlantic_precision]\n",
        "recall_amazon_on_atlantic = [unet_amazon_on_atlantic_recall, am_unet_amazon_on_atlantic_recall, resnet_4d_amazon_on_atlantic_recall, fcn32_4d_amazon_on_atlantic_recall]\n",
        "f1_scores_amazon_on_atlantic = [unet_amazon_on_atlantic_f1_score, am_unet_amazon_on_atlantic_f1_score, resnet_4d_amazon_on_atlantic_f1_score, fcn32_4d_amazon_on_atlantic_f1_score]\n",
        "\n",
        "metrics_4d_amazon_on_atlantic = {'classifier': ['U-Net', 'Attention U-Net', 'ResNet50-SegNet', 'FCN32-VGG16'],\n",
        "              'accuracy': [np.mean(n) for n in scores_amazon_on_atlantic],\n",
        "              'precision': [np.mean(n) for n in precision_amazon_on_atlantic],\n",
        "              'recall': [np.mean(n) for n in recall_amazon_on_atlantic],\n",
        "              'f1_score': [np.mean(n) for n in f1_scores_amazon_on_atlantic],\n",
        "              'accuracy_std': [np.std(n) for n in scores_amazon_on_atlantic],\n",
        "              'precision_std': [np.std(n) for n in precision_amazon_on_atlantic],\n",
        "              'recall_std': [np.std(n) for n in recall_amazon_on_atlantic]\n",
        "              }\n",
        "metrics_4d_amazon_on_atlantic = pd.DataFrame(metrics_4d_amazon_on_atlantic)\n",
        "metrics_4d_amazon_on_atlantic.to_csv('metrics_4d_amazon_on_atlantic.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OunQa23t7mwA"
      },
      "source": [
        "scores_atlantic_on_amazon = [unet_atlantic_on_amazon_score, am_unet_atlantic_on_amazon_score, resnet_4d_atlantic_on_amazon_score, fcn32_4d_atlantic_on_amazon_score]\n",
        "precision_atlantic_on_amazon = [unet_atlantic_on_amazon_precision, am_unet_atlantic_on_amazon_precision, resnet_4d_atlantic_on_amazon_precision, fcn32_4d_atlantic_on_amazon_precision]\n",
        "recall_atlantic_on_amazon = [unet_atlantic_on_amazon_recall, am_unet_atlantic_on_amazon_recall, resnet_4d_atlantic_on_amazon_recall, fcn32_4d_atlantic_on_amazon_recall]\n",
        "f1_scores_atlantic_on_amazon = [unet_atlantic_on_amazon_f1_score, am_unet_atlantic_on_amazon_f1_score, resnet_4d_atlantic_on_amazon_f1_score, fcn32_4d_atlantic_on_amazon_f1_score]\n",
        "\n",
        "metrics_4d_atlantic_on_amazon = {'classifier': ['U-Net', 'Attention U-Net', 'ResNet50-SegNet', 'FCN32-VGG16'],\n",
        "              'accuracy': [np.mean(n) for n in scores_atlantic_on_amazon],\n",
        "              'precision': [np.mean(n) for n in precision_atlantic_on_amazon],\n",
        "              'recall': [np.mean(n) for n in recall_atlantic_on_amazon],\n",
        "              'f1_score': [np.mean(n) for n in f1_scores_atlantic_on_amazon],\n",
        "              'accuracy_std': [np.std(n) for n in scores_atlantic_on_amazon],\n",
        "              'precision_std': [np.std(n) for n in precision_atlantic_on_amazon],\n",
        "              'recall_std': [np.std(n) for n in recall_atlantic_on_amazon]\n",
        "              }\n",
        "metrics_4d_atlantic_on_amazon = pd.DataFrame(metrics_4d_atlantic_on_amazon)\n",
        "metrics_4d_atlantic_on_amazon.to_csv('metrics_4d_atlantic_on_amazon.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}